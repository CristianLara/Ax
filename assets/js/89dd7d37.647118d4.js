"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[974],{5710:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>i,metadata:()=>l,toc:()=>p});var o=t(4848),a=t(8453),r=t(8987);t(1023),t(290);const i={title:"Loop API",sidebar_label:"Loop API"},s="Loop API Example on Hartmann6",l={id:"tutorials/gpei_hartmann_loop/index",title:"Loop API",description:"<LinkButtons",source:"@site/../docs/tutorials/gpei_hartmann_loop/index.mdx",sourceDirName:"tutorials/gpei_hartmann_loop",slug:"/tutorials/gpei_hartmann_loop/",permalink:"/Ax/docs/tutorials/gpei_hartmann_loop/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"Loop API",sidebar_label:"Loop API"},sidebar:"tutorials",previous:{title:"[RECOMMENDED] Service API",permalink:"/Ax/docs/tutorials/gpei_hartmann_service/"},next:{title:"Developer API",permalink:"/Ax/docs/tutorials/gpei_hartmann_developer/"}},c={},p=[{value:"1. Define evaluation function",id:"1-define-evaluation-function",level:2},{value:"2. Run optimization",id:"2-run-optimization",level:2},{value:"3. Plot results",id:"3-plot-results",level:2}];function m(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(r.A,{githubUrl:"",colabUrl:""}),"\n",(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"loop-api-example-on-hartmann6",children:"Loop API Example on Hartmann6"})}),"\n",(0,o.jsxs)(e.p,{children:["The loop API is the most lightweight way to do optimization in Ax. The user makes one\ncall to ",(0,o.jsx)(e.code,{children:"optimize"}),", which performs all of the optimization under the hood and returns\nthe optimized parameters."]}),"\n",(0,o.jsx)(e.p,{children:"For more customizability of the optimization procedure, consider the Service or\nDeveloper API."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom ax.metrics.branin import branin\n\nfrom ax.plot.contour import plot_contour\nfrom ax.plot.trace import optimization_trace_single_method\nfrom ax.service.managed_loop import optimize\nfrom ax.utils.measurement.synthetic_functions import hartmann6\nfrom ax.utils.notebook.plotting import init_notebook_plotting, render\n\ninit_notebook_plotting()\n"})}),"\n",(0,o.jsx)(e.h2,{id:"1-define-evaluation-function",children:"1. Define evaluation function"}),"\n",(0,o.jsx)(e.p,{children:"First, we define an evaluation function that is able to compute all the metrics needed\nfor this experiment. This function needs to accept a set of parameter values and can\nalso accept a weight. It should produce a dictionary of metric names to tuples of mean\nand standard error for those metrics."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def hartmann_evaluation_function(parameterization):\n    x = np.array([parameterization.get(f"x{i+1}") for i in range(6)])\n    # In our case, standard error is 0, since we are computing a synthetic function.\n    return {"hartmann6": (hartmann6(x), 0.0), "l2norm": (np.sqrt((x**2).sum()), 0.0)}\n'})}),"\n",(0,o.jsx)(e.p,{children:'If there is only one metric in the experiment \u2013 the objective \u2013 then evaluation function\ncan return a single tuple of mean and SEM, in which case Ax will assume that evaluation\ncorresponds to the objective. It can also return only the mean as a float, in which case\nAx will treat SEM as unknown and use a model that can infer it. For more details on\nevaluation function, refer to the "Trial Evaluation" section in the docs.'}),"\n",(0,o.jsx)(e.h2,{id:"2-run-optimization",children:"2. Run optimization"}),"\n",(0,o.jsx)(e.p,{children:"The setup for the loop is fully compatible with JSON. The optimization algorithm is\nselected based on the properties of the problem search space."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'best_parameters, values, experiment, model = optimize(\n    parameters=[\n        {\n            "name": "x1",\n            "type": "range",\n            "bounds": [0.0, 1.0],\n            "value_type": "float",  # Optional, defaults to inference from type of "bounds".\n            "log_scale": False,  # Optional, defaults to False.\n        },\n        {\n            "name": "x2",\n            "type": "range",\n            "bounds": [0.0, 1.0],\n        },\n        {\n            "name": "x3",\n            "type": "range",\n            "bounds": [0.0, 1.0],\n        },\n        {\n            "name": "x4",\n            "type": "range",\n            "bounds": [0.0, 1.0],\n        },\n        {\n            "name": "x5",\n            "type": "range",\n            "bounds": [0.0, 1.0],\n        },\n        {\n            "name": "x6",\n            "type": "range",\n            "bounds": [0.0, 1.0],\n        },\n    ],\n    experiment_name="test",\n    objective_name="hartmann6",\n    evaluation_function=hartmann_evaluation_function,\n    minimize=True,  # Optional, defaults to False.\n    parameter_constraints=["x1 + x2 <= 20"],  # Optional.\n    outcome_constraints=["l2norm <= 1.25"],  # Optional.\n    total_trials=30,  # Optional.\n)\n'})}),"\n",(0,o.jsx)(e.p,{children:"And we can introspect optimization results:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"best_parameters\n"})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"means, covariances = values\nmeans\n"})}),"\n",(0,o.jsx)(e.p,{children:"For comparison, minimum of Hartmann6 is:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"hartmann6.fmin\n"})}),"\n",(0,o.jsx)(e.h2,{id:"3-plot-results",children:"3. Plot results"}),"\n",(0,o.jsx)(e.p,{children:'Here we arbitrarily select "x1" and "x2" as the two parameters to plot for both metrics,\n"hartmann6" and "l2norm".'}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'render(plot_contour(model=model, param_x="x1", param_y="x2", metric_name="hartmann6"))\n'})}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'render(plot_contour(model=model, param_x="x1", param_y="x2", metric_name="l2norm"))\n'})}),"\n",(0,o.jsx)(e.p,{children:"We also plot optimization trace, which shows best hartmann6 objective value seen by each\niteration of the optimization:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# `plot_single_method` expects a 2-d array of means, because it expects to average means from multiple\n# optimization runs, so we wrap out best objectives array in another array.\nbest_objectives = np.array(\n    [[trial.objective_mean for trial in experiment.trials.values()]]\n)\nbest_objective_plot = optimization_trace_single_method(\n    y=np.minimum.accumulate(best_objectives, axis=1),\n    optimum=hartmann6.fmin,\n    title="Model performance vs. # of iterations",\n    ylabel="Hartmann6",\n)\nrender(best_objective_plot)\n'})})]})}function d(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(m,{...n})}):m(n)}},1023:(n,e,t)=>{t.d(e,{A:()=>u});t(6540);var o,a=new Uint8Array(16);function r(){if(!o&&!(o="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return o(a)}const i=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;const s=function(n){return"string"==typeof n&&i.test(n)};for(var l=[],c=0;c<256;++c)l.push((c+256).toString(16).substr(1));const p=function(n){var e=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,t=(l[n[e+0]]+l[n[e+1]]+l[n[e+2]]+l[n[e+3]]+"-"+l[n[e+4]]+l[n[e+5]]+"-"+l[n[e+6]]+l[n[e+7]]+"-"+l[n[e+8]]+l[n[e+9]]+"-"+l[n[e+10]]+l[n[e+11]]+l[n[e+12]]+l[n[e+13]]+l[n[e+14]]+l[n[e+15]]).toLowerCase();if(!s(t))throw TypeError("Stringified UUID is invalid");return t};const m=function(n,e,t){var o=(n=n||{}).random||(n.rng||r)();if(o[6]=15&o[6]|64,o[8]=63&o[8]|128,e){t=t||0;for(var a=0;a<16;++a)e[t+a]=o[a];return e}return p(o)};var d=t(4848);const u=function(n){return(0,d.jsxs)("div",{style:{backgroundColor:"lightgray",marginBottom:"var(--ifm-leading)",borderRadius:"var(--ifm-global-radius)",boxShadow:"var(--ifm-global-shadow-lw)",overflow:"hidden",padding:"10px",font:"var(--ifm-code-font-size) / var(--ifm-pre-line-height) var(--ifm-font-family-monospace)"},children:[(0,d.jsx)("span",{style:{color:"red"},children:"Out: "}),(0,d.jsx)("pre",{style:{margin:"0px",backgroundColor:"inherit"},children:n.children.split("\n").map((function(n){return(0,d.jsx)("p",{style:{marginBottom:"0px"},children:n},m())}))})]})}},8987:(n,e,t)=>{t.d(e,{A:()=>r});t(6540);var o=t(8774),a=t(4848);const r=function(n){var e=n.githubUrl,t=n.colabUrl;return(0,a.jsxs)("div",{className:"link-buttons",children:[(0,a.jsx)(o.A,{to:e,children:"Open in GitHub"}),(0,a.jsx)("div",{}),(0,a.jsx)(o.A,{to:t,children:"Run in Google Colab"})]})}},290:(n,e,t)=>{t(6540);var o=t(3259),a=t.n(o),r=(t(2303),t(4848));a()({loader:function(){return t.e(236).then(t.bind(t,1236))},loading:function(n){return n.timedOut?(0,r.jsx)("blockquote",{children:"Error: Loading Plotly timed out."}):(0,r.jsx)("div",{children:"loading..."})},timeout:1e4})},8453:(n,e,t)=>{t.d(e,{R:()=>i,x:()=>s});var o=t(6540);const a={},r=o.createContext(a);function i(n){const e=o.useContext(r);return o.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:i(n.components),o.createElement(r.Provider,{value:e},n.children)}}}]);