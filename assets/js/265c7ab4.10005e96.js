"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[129],{1146:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var a=n(4848),i=n(8453),r=n(8987);n(1023),n(290);const o={title:"Hyperparameter Optimization for PyTorch",sidebar_label:"Hyperparameter Optimization for PyTorch"},s="Tune a CNN on MNIST",l={id:"tutorials/tune_cnn_service/index",title:"Hyperparameter Optimization for PyTorch",description:"<LinkButtons",source:"@site/../docs/tutorials/tune_cnn_service/index.mdx",sourceDirName:"tutorials/tune_cnn_service",slug:"/tutorials/tune_cnn_service/",permalink:"/Ax/docs/tutorials/tune_cnn_service/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"Hyperparameter Optimization for PyTorch",sidebar_label:"Hyperparameter Optimization for PyTorch"},sidebar:"tutorials",previous:{title:"Modular `BoTorchModel`",permalink:"/Ax/docs/tutorials/modular_botax/"},next:{title:"Hyperparameter Optimization on SLURM via SubmitIt",permalink:"/Ax/docs/tutorials/submitit/"}},c={},d=[{value:"1. Load MNIST data",id:"1-load-mnist-data",level:2},{value:"2. Initialize Client",id:"2-initialize-client",level:2},{value:"3. Set up experiment",id:"3-set-up-experiment",level:2},{value:"4. Define how to evaluate trials",id:"4-define-how-to-evaluate-trials",level:2},{value:"5. Run optimization loop",id:"5-run-optimization-loop",level:2},{value:"How many trials can run in parallel?",id:"how-many-trials-can-run-in-parallel",level:3},{value:"How to view all existing trials during optimization?",id:"how-to-view-all-existing-trials-during-optimization",level:3},{value:"6. Retrieve best parameters",id:"6-retrieve-best-parameters",level:2},{value:"7. Plot the response surface and optimization trace",id:"7-plot-the-response-surface-and-optimization-trace",level:2},{value:"8. Train CNN with best hyperparameters and evaluate on test set",id:"8-train-cnn-with-best-hyperparameters-and-evaluate-on-test-set",level:2},{value:"9. Save / reload optimization to JSON / SQL",id:"9-save--reload-optimization-to-json--sql",level:2}];function h(e){const t={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(r.A,{githubUrl:"",colabUrl:""}),"\n",(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"tune-a-cnn-on-mnist",children:"Tune a CNN on MNIST"})}),"\n",(0,a.jsx)(t.p,{children:"This tutorial walks through using Ax to tune two hyperparameters (learning rate and\nmomentum) for a PyTorch CNN on the MNIST dataset trained using SGD with momentum."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"import torch\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\nfrom ax.service.utils.report_utils import exp_to_df\nfrom ax.utils.notebook.plotting import init_notebook_plotting, render\nfrom ax.utils.tutorials.cnn_utils import evaluate, load_mnist, train\nfrom torch._tensor import Tensor\nfrom torch.utils.data import DataLoader\n\ninit_notebook_plotting()\n"})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'torch.manual_seed(42)\ndtype = torch.float\ndevice = torch.device("cuda" if torch.cuda.is_available() else "cpu")\n'})}),"\n",(0,a.jsx)(t.h2,{id:"1-load-mnist-data",children:"1. Load MNIST data"}),"\n",(0,a.jsx)(t.p,{children:"First, we need to load the MNIST data and partition it into training, validation, and\ntest sets."}),"\n",(0,a.jsx)(t.p,{children:"Note: this will download the dataset if necessary."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"BATCH_SIZE = 512\ntrain_loader, valid_loader, test_loader = load_mnist(batch_size=BATCH_SIZE)\n"})}),"\n",(0,a.jsx)(t.h2,{id:"2-initialize-client",children:"2. Initialize Client"}),"\n",(0,a.jsx)(t.p,{children:"Create a client object to interface with Ax APIs. By default this runs locally without\nstorage."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"ax_client = AxClient()\n"})}),"\n",(0,a.jsx)(t.h2,{id:"3-set-up-experiment",children:"3. Set up experiment"}),"\n",(0,a.jsxs)(t.p,{children:["An experiment consists of a ",(0,a.jsx)(t.strong,{children:"search space"})," (parameters and parameter constraints) and\n",(0,a.jsx)(t.strong,{children:"optimization configuration"})," (objective name, minimization setting, and outcome\nconstraints)."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'# Create an experiment with required arguments: name, parameters, and objective_name.\nax_client.create_experiment(\n    name="tune_cnn_on_mnist",  # The name of the experiment.\n    parameters=[\n        {\n            "name": "lr",  # The name of the parameter.\n            "type": "range",  # The type of the parameter ("range", "choice" or "fixed").\n            "bounds": [1e-6, 0.4],  # The bounds for range parameters. \n            # "values" The possible values for choice parameters .\n            # "value" The fixed value for fixed parameters.\n            "value_type": "float",  # Optional, the value type ("int", "float", "bool" or "str"). Defaults to inference from type of "bounds".\n            "log_scale": True,  # Optional, whether to use a log scale for range parameters. Defaults to False.\n            # "is_ordered" Optional, a flag for choice parameters.\n        },\n        {\n            "name": "momentum",  \n            "type": "range",  \n            "bounds": [0.0, 1.0],  \n        },\n    ],\n    objectives={"accuracy": ObjectiveProperties(minimize=False)},  # The objective name and minimization setting.\n    # parameter_constraints: Optional, a list of strings of form "p1 >= p2" or "p1 + p2 <= some_bound".\n    # outcome_constraints: Optional, a list of strings of form "constrained_metric <= some_bound".\n)\n'})}),"\n",(0,a.jsx)(t.h2,{id:"4-define-how-to-evaluate-trials",children:"4. Define how to evaluate trials"}),"\n",(0,a.jsx)(t.p,{children:"First we define a simple CNN class to classify the MNIST images"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"class CNN(nn.Module):\n    \n    def __init__(self) -> None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, stride=1)\n        self.fc1 = nn.Linear(8 * 8 * 20, 64)\n        self.fc2 = nn.Linear(64, 10)\n\n    def forward(self, x: Tensor) -> Tensor:\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 3, 3)\n        x = x.view(-1, 8 * 8 * 20)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n"})}),"\n",(0,a.jsxs)(t.p,{children:["In this tutorial, we want to optimize classification accuracy on the validation set as a\nfunction of the learning rate and momentum. The ",(0,a.jsx)(t.code,{children:"train_evaluate"})," function takes in a\nparameterization (set of parameter values), computes the classification accuracy, and\nreturns that metric."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'def train_evaluate(parameterization):\n    """\n    Train the model and then compute an evaluation metric.\n\n    In this tutorial, the CNN utils package is doing a lot of work\n    under the hood:\n        - `train` initializes the network, defines the loss function\n        and optimizer, performs the training loop, and returns the\n        trained model.\n        - `evaluate` computes the accuracy of the model on the\n        evaluation dataset and returns the metric.\n\n    For your use case, you can define training and evaluation functions\n    of your choosing.\n\n    """\n    net = CNN()\n    net = train(\n        net=net,\n        train_loader=train_loader,\n        parameters=parameterization,\n        dtype=dtype,\n        device=device,\n    )\n\n    return evaluate(\n        net=net, \n        data_loader=valid_loader, \n        dtype=dtype, \n        device=device,\n    )\n\n'})}),"\n",(0,a.jsx)(t.h2,{id:"5-run-optimization-loop",children:"5. Run optimization loop"}),"\n",(0,a.jsxs)(t.p,{children:["First we use ",(0,a.jsx)(t.code,{children:"attach_trial"})," to attach a custom trial with manually-chosen parameters.\nThis step is optional, but we include it here to demonstrate adding manual trials and to\nserve as a baseline model with decent performance."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'# Attach the trial\nax_client.attach_trial(\n    parameters={"lr": 0.000026, "momentum": 0.58}\n)\n\n# Get the parameters and run the trial \nbaseline_parameters = ax_client.get_trial_parameters(trial_index=0)\nax_client.complete_trial(trial_index=0, raw_data=train_evaluate(baseline_parameters))\n'})}),"\n",(0,a.jsx)(t.p,{children:"Now we start the optimization loop."}),"\n",(0,a.jsx)(t.p,{children:"At each step, the user queries the client for a new trial then submits the evaluation of\nthat trial back to the client."}),"\n",(0,a.jsxs)(t.p,{children:["Note that Ax auto-selects an appropriate optimization algorithm based on the search\nspace. For more advanced use cases that require a specific optimization algorithm, pass\na ",(0,a.jsx)(t.code,{children:"generation_strategy"})," argument into the ",(0,a.jsx)(t.code,{children:"AxClient"})," constructor. Note that when\nBayesian Optimization is used, generating new trials may take a few minutes."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"for i in range(25):\n    parameters, trial_index = ax_client.get_next_trial()\n    # Local evaluation here can be replaced with deployment to external system.\n    ax_client.complete_trial(trial_index=trial_index, raw_data=train_evaluate(parameters))\n"})}),"\n",(0,a.jsx)(t.h3,{id:"how-many-trials-can-run-in-parallel",children:"How many trials can run in parallel?"}),"\n",(0,a.jsx)(t.p,{children:"By default, Ax restricts number of trials that can run in parallel for some optimization\nstages, in order to improve the optimization performance and reduce the number of trials\nthat the optimization will require. To check the maximum parallelism for each\noptimization stage:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"ax_client.get_max_parallelism()\n"})}),"\n",(0,a.jsx)(t.p,{children:"The output of this function is a list of tuples of form (number of trials, max\nparallelism), so the example above means \"the max parallelism is 5 for the first 5\ntrials and 3 for all subsequent trials.\" This is because the first 5 trials are produced\nquasi-randomly and can all be evaluated at once, and subsequent trials are produced via\nBayesian optimization, which converges on optimal point in fewer trials when parallelism\nis limited. MaxParallelismReachedException indicates that the parallelism limit has been\nreached \u2013\u2013 refer to the 'Service API Exceptions Meaning and Handling' section at the end\nof the tutorial for handling."}),"\n",(0,a.jsx)(t.h3,{id:"how-to-view-all-existing-trials-during-optimization",children:"How to view all existing trials during optimization?"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"ax_client.get_trials_data_frame()\n"})}),"\n",(0,a.jsx)(t.h2,{id:"6-retrieve-best-parameters",children:"6. Retrieve best parameters"}),"\n",(0,a.jsxs)(t.p,{children:["Once it's complete, we can access the best parameters found, as well as the\ncorresponding metric values. Note that these parameters may not necessarily be the set\nthat yielded the highest ",(0,a.jsx)(t.em,{children:"observed"})," accuracy because Ax uses the highest model\n",(0,a.jsx)(t.em,{children:"predicted"})," accuracy to choose the best parameters (see\n",(0,a.jsx)(t.a,{href:"https://ax.dev/api/service.html#module-ax.service.utils.best_point_mixin",children:"here"})," for\nmore details). Due to randomness in the data or the algorithm itself, using observed\naccuracy may result in choosing an outlier for the best set of parameters. Using the\nmodel predicted best will use the model to regularize the observations and reduce the\nlikelihood of picking some outlier in the data."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"best_parameters, values = ax_client.get_best_parameters()\nbest_parameters\n"})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"mean, covariance = values\nmean\n"})}),"\n",(0,a.jsx)(t.h2,{id:"7-plot-the-response-surface-and-optimization-trace",children:"7. Plot the response surface and optimization trace"}),"\n",(0,a.jsx)(t.p,{children:"Contour plot showing classification accuracy as a function of the two hyperparameters."}),"\n",(0,a.jsx)(t.p,{children:"The black squares show points that we have actually run; notice how they are clustered\nin the optimal region."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'render(ax_client.get_contour_plot(param_x="lr", param_y="momentum", metric_name="accuracy"))\n'})}),"\n",(0,a.jsx)(t.p,{children:"Here we plot the optimization trace, showing the progression of finding the point with\nthe optimal objective:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"render(\n    ax_client.get_optimization_trace()\n)  \n"})}),"\n",(0,a.jsx)(t.h2,{id:"8-train-cnn-with-best-hyperparameters-and-evaluate-on-test-set",children:"8. Train CNN with best hyperparameters and evaluate on test set"}),"\n",(0,a.jsx)(t.p,{children:"Note that the resulting accuracy on the test set generally won't be the same as the\nmaximum accuracy achieved on the evaluation set throughout optimization."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'df = ax_client.get_trials_data_frame()\nbest_arm_idx = df.trial_index[df["accuracy"] == df["accuracy"].max()].values[0]\nbest_arm = ax_client.get_trial_parameters(best_arm_idx)\nbest_arm\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"combined_train_valid_set = torch.utils.data.ConcatDataset(\n    [\n        train_loader.dataset.dataset,\n        valid_loader.dataset.dataset,\n    ]\n)\ncombined_train_valid_loader = torch.utils.data.DataLoader(\n    combined_train_valid_set,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n)\n"})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"net = train(\n    net=CNN(),\n    train_loader=combined_train_valid_loader,\n    parameters=best_arm,\n    dtype=dtype,\n    device=device,\n)\ntest_accuracy = evaluate(\n    net=net,\n    data_loader=test_loader,\n    dtype=dtype,\n    device=device,\n)\n"})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'print(f"Classification Accuracy (test set): {round(test_accuracy*100, 2)}%")\n'})}),"\n",(0,a.jsx)(t.h2,{id:"9-save--reload-optimization-to-json--sql",children:"9. Save / reload optimization to JSON / SQL"}),"\n",(0,a.jsxs)(t.p,{children:["We can serialize the state of optimization to JSON and save it to a ",(0,a.jsx)(t.code,{children:".json"})," file or save\nit to the SQL backend. For the former:"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"ax_client.save_to_json_file()  # For custom filepath, pass `filepath` argument.\n"})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"restored_ax_client = (\n    AxClient.load_from_json_file()\n)  # For custom filepath, pass `filepath` argument.\n"})}),"\n",(0,a.jsxs)(t.p,{children:["To store state of optimization to an SQL backend, first follow\n",(0,a.jsx)(t.a,{href:"https://ax.dev/docs/storage.html#sql",children:"setup instructions"})," on Ax website."]}),"\n",(0,a.jsxs)(t.p,{children:["Having set up the SQL backend, pass ",(0,a.jsx)(t.code,{children:"DBSettings"})," to ",(0,a.jsx)(t.code,{children:"AxClient"})," on instantiation (note\nthat ",(0,a.jsx)(t.code,{children:"SQLAlchemy"})," dependency will have to be installed \u2013 for installation, refer to\n",(0,a.jsx)(t.a,{href:"https://ax.dev/docs/installation.html#optional-dependencies",children:"optional dependencies"})," on\nAx website):"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'from ax.storage.sqa_store.structs import DBSettings\n\n# URL is of the form "dialect+driver://username:password@host:port/database".\ndb_settings = DBSettings(url="sqlite:///foo.db")\n# Instead of URL, can provide a `creator function`; can specify custom encoders/decoders if necessary.\nnew_ax = AxClient(db_settings=db_settings)\n'})}),"\n",(0,a.jsxs)(t.p,{children:["When valid ",(0,a.jsx)(t.code,{children:"DBSettings"})," are passed into ",(0,a.jsx)(t.code,{children:"AxClient"}),", a unique experiment name is a\nrequired argument (",(0,a.jsx)(t.code,{children:"name"}),") to ",(0,a.jsx)(t.code,{children:"ax_client.create_experiment"}),". The ",(0,a.jsx)(t.strong,{children:"state of the\noptimization is auto-saved"})," any time it changes (i.e. a new trial is added or\ncompleted, etc)."]}),"\n",(0,a.jsxs)(t.p,{children:["To reload an optimization state later, instantiate ",(0,a.jsx)(t.code,{children:"AxClient"})," with the same ",(0,a.jsx)(t.code,{children:"DBSettings"}),"\nand use ",(0,a.jsx)(t.code,{children:'ax_client.load_experiment_from_database(experiment_name="my_experiment")'}),"."]}),"\n",(0,a.jsx)(t.h1,{id:"special-cases",children:"Special Cases"}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Evaluation failure"}),": should any optimization iterations fail during evaluation,\n",(0,a.jsx)(t.code,{children:"log_trial_failure"})," will ensure that the same trial is not proposed again."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"_, trial_index = ax_client.get_next_trial()\nax_client.log_trial_failure(trial_index=trial_index)\n"})}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Need to run many trials in parallel"}),": for optimal results and optimization\nefficiency, we strongly recommend sequential optimization (generating a few trials, then\nwaiting for them to be completed with evaluation data). However, if your use case needs\nto dispatch many trials in parallel before they are updated with data and you are\nrunning into the ",(0,a.jsx)(t.em,{children:'"All trials for current model have been generated, but not enough data\nhas been observed to fit next model"'})," error, instantiate ",(0,a.jsx)(t.code,{children:"AxClient"})," as\n",(0,a.jsx)(t.code,{children:"AxClient(enforce_sequential_optimization=False)"}),"."]}),"\n",(0,a.jsx)(t.h1,{id:"service-api-exceptions-meaning-and-handling",children:"Service API Exceptions Meaning and Handling"}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://ax.dev/api/exceptions.html#ax.exceptions.core.DataRequiredError",children:(0,a.jsx)(t.strong,{children:(0,a.jsx)(t.code,{children:"DataRequiredError"})})}),":\nAx generation strategy needs to be updated with more data to proceed to the next\noptimization model. When the optimization moves from initialization stage to the\nBayesian optimization stage, the underlying BayesOpt model needs sufficient data to\ntrain. For optimal results and optimization efficiency (finding the optimal point in the\nleast number of trials), we recommend sequential optimization (generating a few trials,\nthen waiting for them to be completed with evaluation data). Therefore, the correct way\nto handle this exception is to wait until more trial evaluations complete and log their\ndata via ",(0,a.jsx)(t.code,{children:"ax_client.complete_trial(...)"}),"."]}),"\n",(0,a.jsxs)(t.p,{children:["However, if there is strong need to generate more trials before more data is available,\ninstantiate ",(0,a.jsx)(t.code,{children:"AxClient"})," as ",(0,a.jsx)(t.code,{children:"AxClient(enforce_sequential_optimization=False)"}),". With this\nsetting, as many trials will be generated from the initialization stage as requested,\nand the optimization will move to the BayesOpt stage whenever enough trials are\ncompleted."]}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://ax.dev/api/modelbridge.html#ax.modelbridge.generation_strategy.MaxParallelismReachedException",children:(0,a.jsx)(t.strong,{children:(0,a.jsx)(t.code,{children:"MaxParallelismReachedException"})})}),":\ngeneration strategy restricts the number of trials that can be run simultaneously (to\nencourage sequential optimization), and the parallelism limit has been reached. The\ncorrect way to handle this exception is the same as ",(0,a.jsx)(t.code,{children:"DataRequiredError"})," \u2013 to wait until\nmore trial evluations complete and log their data via ",(0,a.jsx)(t.code,{children:"ax_client.complete_trial(...)"}),"."]}),"\n",(0,a.jsxs)(t.p,{children:["In some cases higher parallelism is important, so\n",(0,a.jsx)(t.code,{children:"enforce_sequential_optimization=False"})," kwarg to AxClient allows the user to suppress\nlimiting of parallelism. It's also possible to override the default parallelism setting\nfor all stages of the optimization by passing ",(0,a.jsx)(t.code,{children:"choose_generation_strategy_kwargs"})," to\n",(0,a.jsx)(t.code,{children:"ax_client.create_experiment"}),":"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'ax_client = AxClient()\nax_client.create_experiment(\n    parameters=[\n        {"name": "x", "type": "range", "bounds": [-5.0, 10.0]},\n        {"name": "y", "type": "range", "bounds": [0.0, 15.0]},\n    ],\n    # Sets max parallelism to 10 for all steps of the generation strategy.\n    choose_generation_strategy_kwargs={"max_parallelism_override": 10},\n)\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"ax_client.get_max_parallelism()  # Max parallelism is now 10 for all stages of the optimization.\n"})})]})}function p(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},1023:(e,t,n)=>{n.d(t,{A:()=>m});n(6540);var a,i=new Uint8Array(16);function r(){if(!a&&!(a="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return a(i)}const o=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;const s=function(e){return"string"==typeof e&&o.test(e)};for(var l=[],c=0;c<256;++c)l.push((c+256).toString(16).substr(1));const d=function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,n=(l[e[t+0]]+l[e[t+1]]+l[e[t+2]]+l[e[t+3]]+"-"+l[e[t+4]]+l[e[t+5]]+"-"+l[e[t+6]]+l[e[t+7]]+"-"+l[e[t+8]]+l[e[t+9]]+"-"+l[e[t+10]]+l[e[t+11]]+l[e[t+12]]+l[e[t+13]]+l[e[t+14]]+l[e[t+15]]).toLowerCase();if(!s(n))throw TypeError("Stringified UUID is invalid");return n};const h=function(e,t,n){var a=(e=e||{}).random||(e.rng||r)();if(a[6]=15&a[6]|64,a[8]=63&a[8]|128,t){n=n||0;for(var i=0;i<16;++i)t[n+i]=a[i];return t}return d(a)};var p=n(4848);const m=function(e){return(0,p.jsxs)("div",{style:{backgroundColor:"lightgray",marginBottom:"var(--ifm-leading)",borderRadius:"var(--ifm-global-radius)",boxShadow:"var(--ifm-global-shadow-lw)",overflow:"hidden",padding:"10px",font:"var(--ifm-code-font-size) / var(--ifm-pre-line-height) var(--ifm-font-family-monospace)"},children:[(0,p.jsx)("span",{style:{color:"red"},children:"Out: "}),(0,p.jsx)("pre",{style:{margin:"0px",backgroundColor:"inherit"},children:e.children.split("\n").map((function(e){return(0,p.jsx)("p",{style:{marginBottom:"0px"},children:e},h())}))})]})}},8987:(e,t,n)=>{n.d(t,{A:()=>r});n(6540);var a=n(8774),i=n(4848);const r=function(e){var t=e.githubUrl,n=e.colabUrl;return(0,i.jsxs)("div",{className:"link-buttons",children:[(0,i.jsx)(a.A,{to:t,children:"Open in GitHub"}),(0,i.jsx)("div",{}),(0,i.jsx)(a.A,{to:n,children:"Run in Google Colab"})]})}},290:(e,t,n)=>{n(6540);var a=n(3259),i=n.n(a),r=(n(2303),n(4848));i()({loader:function(){return n.e(236).then(n.bind(n,1236))},loading:function(e){return e.timedOut?(0,r.jsx)("blockquote",{children:"Error: Loading Plotly timed out."}):(0,r.jsx)("div",{children:"loading..."})},timeout:1e4})},8453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>s});var a=n(6540);const i={},r=a.createContext(i);function o(e){const t=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(r.Provider,{value:t},e.children)}}}]);