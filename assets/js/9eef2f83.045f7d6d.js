"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[319],{3442:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var r=t(4848),a=t(8453),i=t(8987);t(1023),t(290);const o={title:"Developer API",sidebar_label:"Developer API"},s="Developer API Example on Hartmann6",l={id:"tutorials/gpei_hartmann_developer/index",title:"Developer API",description:"<LinkButtons",source:"@site/../docs/tutorials/gpei_hartmann_developer/index.mdx",sourceDirName:"tutorials/gpei_hartmann_developer",slug:"/tutorials/gpei_hartmann_developer/",permalink:"/Ax/docs/tutorials/gpei_hartmann_developer/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"Developer API",sidebar_label:"Developer API"},sidebar:"tutorials",previous:{title:"Loop API",permalink:"/Ax/docs/tutorials/gpei_hartmann_loop/"},next:{title:"Visualizations",permalink:"/Ax/docs/tutorials/visualizations/"}},c={},d=[{value:"1. Create Search Space",id:"1-create-search-space",level:2},{value:"2. Create Optimization Config",id:"2-create-optimization-config",level:2},{value:"3. Define a Runner",id:"3-define-a-runner",level:2},{value:"4. Create Experiment",id:"4-create-experiment",level:2},{value:"5. Perform Optimization",id:"5-perform-optimization",level:2},{value:"6. Inspect trials&#39; data",id:"6-inspect-trials-data",level:2},{value:"7. Plot results",id:"7-plot-results",level:2},{value:"8. Defining custom metrics",id:"8-defining-custom-metrics",level:2},{value:"9. Save to JSON or SQL",id:"9-save-to-json-or-sql",level:2}];function m(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.A,{githubUrl:"",colabUrl:""}),"\n",(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"developer-api-example-on-hartmann6",children:"Developer API Example on Hartmann6"})}),"\n",(0,r.jsxs)(n.p,{children:["The Developer API is suitable when the user wants maximal customization of the\noptimization loop. This tutorial demonstrates optimization of a Hartmann6 function using\nthe ",(0,r.jsx)(n.code,{children:"Experiment"})," construct. In this example, trials will be evaluated synchronously."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from ax import (\n    ChoiceParameter,\n    ComparisonOp,\n    Experiment,\n    FixedParameter,\n    Metric,\n    Objective,\n    OptimizationConfig,\n    OrderConstraint,\n    OutcomeConstraint,\n    ParameterType,\n    RangeParameter,\n    SearchSpace,\n    SumConstraint,\n)\nfrom ax.modelbridge.registry import Models\nfrom ax.utils.notebook.plotting import init_notebook_plotting, render\n\ninit_notebook_plotting()\n"})}),"\n",(0,r.jsx)(n.h2,{id:"1-create-search-space",children:"1. Create Search Space"}),"\n",(0,r.jsx)(n.p,{children:"First, we define a search space, which defines the type and allowed range for the\nparameters."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from ax.metrics.l2norm import L2NormMetric\nfrom ax.metrics.hartmann6 import Hartmann6Metric\n\n\nhartmann_search_space = SearchSpace(\n    parameters=[\n        RangeParameter(\n            name=f"x{i}", parameter_type=ParameterType.FLOAT, lower=0.0, upper=1.0\n        )\n        for i in range(6)\n    ]\n)\n'})}),"\n",(0,r.jsx)(n.p,{children:"Note that there are two other parameter classes, FixedParameter and ChoiceParameter.\nAlthough we won't use these in this example, you can create them as follows."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'choice_param = ChoiceParameter(\n    name="choice", values=["foo", "bar"], parameter_type=ParameterType.STRING\n)\nfixed_param = FixedParameter(\n    name="fixed", value=[True], parameter_type=ParameterType.BOOL\n)\n'})}),"\n",(0,r.jsx)(n.p,{children:"Sum constraints enforce that the sum of a set of parameters is greater or less than some\nbound, and order constraints enforce that one parameter is smaller than the other. We\nwon't use these either, but see two examples below."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'sum_constraint = SumConstraint(\n    parameters=[\n        hartmann_search_space.parameters["x0"],\n        hartmann_search_space.parameters["x1"],\n    ],\n    is_upper_bound=True,\n    bound=5.0,\n)\n\norder_constraint = OrderConstraint(\n    lower_parameter=hartmann_search_space.parameters["x0"],\n    upper_parameter=hartmann_search_space.parameters["x1"],\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"2-create-optimization-config",children:"2. Create Optimization Config"}),"\n",(0,r.jsxs)(n.p,{children:["Second, we define the ",(0,r.jsx)(n.code,{children:"optimization_config"})," with an ",(0,r.jsx)(n.code,{children:"objective"})," and\n",(0,r.jsx)(n.code,{children:"outcome_constraints"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["When doing the optimization, we will find points that minimize the objective while\nobeying the constraints (which in this case means ",(0,r.jsx)(n.code,{children:"l2norm < 1.25"}),")."]}),"\n",(0,r.jsxs)(n.p,{children:["Note: we are using ",(0,r.jsx)(n.code,{children:"Hartmann6Metric"})," and ",(0,r.jsx)(n.code,{children:"L2NormMetric"})," here, which have built in\nevaluation functions for testing. For creating your own cutom metrics, see\n",(0,r.jsx)(n.a,{href:"#8.-Defining-custom-metrics",children:"8. Defining custom metrics"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'param_names = [f"x{i}" for i in range(6)]\noptimization_config = OptimizationConfig(\n    objective=Objective(\n        metric=Hartmann6Metric(name="hartmann6", param_names=param_names),\n        minimize=True,\n    ),\n    outcome_constraints=[\n        OutcomeConstraint(\n            metric=L2NormMetric(name="l2norm", param_names=param_names, noise_sd=0.2),\n            op=ComparisonOp.LEQ,\n            bound=1.25,\n            relative=False,\n        )\n    ],\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"3-define-a-runner",children:"3. Define a Runner"}),"\n",(0,r.jsx)(n.p,{children:'Before an experiment can collect data, it must have a Runner attached. A runner handles\nthe deployment of trials. A trial must be "run" before it can be evaluated.'}),"\n",(0,r.jsx)(n.p,{children:"Here, we have a dummy runner that does nothing. In practice, a runner might be in charge\nof pushing an experiment to production."}),"\n",(0,r.jsxs)(n.p,{children:["The only method that needs to be defined for runner subclasses is run, which performs\nany necessary deployment logic, and returns a dictionary of resulting metadata. This\nmetadata can later be accessed through the trial's ",(0,r.jsx)(n.code,{children:"run_metadata"})," property."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from ax import Runner\n\n\nclass MyRunner(Runner):\n    def run(self, trial):\n        trial_metadata = {"name": str(trial.index)}\n        return trial_metadata\n'})}),"\n",(0,r.jsx)(n.h2,{id:"4-create-experiment",children:"4. Create Experiment"}),"\n",(0,r.jsxs)(n.p,{children:["Next, we make an ",(0,r.jsx)(n.code,{children:"Experiment"})," with our search space, runner, and optimization config."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'exp = Experiment(\n    name="test_hartmann",\n    search_space=hartmann_search_space,\n    optimization_config=optimization_config,\n    runner=MyRunner(),\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"5-perform-optimization",children:"5. Perform Optimization"}),"\n",(0,r.jsx)(n.p,{children:"Run the optimization using the settings defined on the experiment. We will create 5\nrandom sobol points for exploration followed by 15 points generated using the GPEI\noptimizer."}),"\n",(0,r.jsxs)(n.p,{children:["Instead of a member of the ",(0,r.jsx)(n.code,{children:"Models"})," enum to produce generator runs, users can leverage a\n",(0,r.jsx)(n.code,{children:"GenerationStrategy"}),". See the\n",(0,r.jsx)(n.a,{href:"https://ax.dev/tutorials/generation_strategy.html",children:"Generation Strategy Tutorial"})," for\nmore info."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from ax.modelbridge.registry import Models\n\nNUM_SOBOL_TRIALS = 5\nNUM_BOTORCH_TRIALS = 15\n\nprint(f"Running Sobol initialization trials...")\nsobol = Models.SOBOL(search_space=exp.search_space)\n\nfor i in range(NUM_SOBOL_TRIALS):\n    # Produce a GeneratorRun from the model, which contains proposed arm(s) and other metadata\n    generator_run = sobol.gen(n=1)\n    # Add generator run to a trial to make it part of the experiment and evaluate arm(s) in it\n    trial = exp.new_trial(generator_run=generator_run)\n    # Start trial run to evaluate arm(s) in the trial\n    trial.run()\n    # Mark trial as completed to record when a trial run is completed\n    # and enable fetching of data for metrics on the experiment\n    # (by default, trials must be completed before metrics can fetch their data,\n    # unless a metric is explicitly configured otherwise)\n    trial.mark_completed()\n\nfor i in range(NUM_BOTORCH_TRIALS):\n    print(\n        f"Running BO trial {i + NUM_SOBOL_TRIALS + 1}/{NUM_SOBOL_TRIALS + NUM_BOTORCH_TRIALS}..."\n    )\n    # Reinitialize GP+EI model at each step with updated data.\n    gpei = Models.BOTORCH_MODULAR(experiment=exp, data=exp.fetch_data())\n    generator_run = gpei.gen(n=1)\n    trial = exp.new_trial(generator_run=generator_run)\n    trial.run()\n    trial.mark_completed()\n\nprint("Done!")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"6-inspect-trials-data",children:"6. Inspect trials' data"}),"\n",(0,r.jsxs)(n.p,{children:["Now we can inspect the ",(0,r.jsx)(n.code,{children:"Experiment"}),"'s data by calling ",(0,r.jsx)(n.code,{children:"fetch_data()"}),", which retrieves\nevaluation data for all trials of the experiment."]}),"\n",(0,r.jsxs)(n.p,{children:["To fetch trial data, we need to run it and mark it completed. For most metrics in Ax,\ndata is only available once the status of the trial is ",(0,r.jsx)(n.code,{children:"COMPLETED"}),", since in real-worlds\nscenarios, metrics can typically only be fetched after the trial finished running."]}),"\n",(0,r.jsxs)(n.p,{children:["NOTE: Metrics classes may implement the ",(0,r.jsx)(n.code,{children:"is_available_while_running"})," method. When this\nmethod returns ",(0,r.jsx)(n.code,{children:"True"}),", data is available when trials are either ",(0,r.jsx)(n.code,{children:"RUNNING"})," or\n",(0,r.jsx)(n.code,{children:"COMPLETED"}),". This can be used to obtain intermediate results from A/B test trials and\nother online experiments, or when metric values are available immediately, like in the\ncase of synthetic problem metrics."]}),"\n",(0,r.jsxs)(n.p,{children:["We can also use the ",(0,r.jsx)(n.code,{children:"fetch_trials_data"})," function to get evaluation data for a specific\ntrials in the experiment, like so:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"trial_data = exp.fetch_trials_data([NUM_SOBOL_TRIALS + NUM_BOTORCH_TRIALS - 1])\ntrial_data.df\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The below call to ",(0,r.jsx)(n.code,{children:"exp.fetch_data()"})," also attaches data to the last trial, which because\nof the way we looped through Botorch trials in\n",(0,r.jsx)(n.a,{href:"5.-Perform-Optimization",children:"5. Perform Optimization"}),", would otherwise not have data\nattached. This is necessary to get ",(0,r.jsx)(n.code,{children:"objective_means"})," in\n",(0,r.jsx)(n.a,{href:"7.-Plot-results",children:"7. Plot results"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"exp.fetch_data().df\n"})}),"\n",(0,r.jsx)(n.h2,{id:"7-plot-results",children:"7. Plot results"}),"\n",(0,r.jsx)(n.p,{children:"Now we can plot the results of our optimization:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import numpy as np\nfrom ax.plot.trace import optimization_trace_single_method\n\n# `plot_single_method` expects a 2-d array of means, because it expects to average means from multiple\n# optimization runs, so we wrap out best objectives array in another array.\nobjective_means = np.array([[trial.objective_mean for trial in exp.trials.values()]])\nbest_objective_plot = optimization_trace_single_method(\n    y=np.minimum.accumulate(objective_means, axis=1),\n    optimum=-3.32237,  # Known minimum objective for Hartmann6 function.\n)\nrender(best_objective_plot)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"8-defining-custom-metrics",children:"8. Defining custom metrics"}),"\n",(0,r.jsx)(n.p,{children:"In order to perform an optimization, we also need to define an optimization config for\nthe experiment. An optimization config is composed of an objective metric to be\nminimized or maximized in the experiment, and optionally a set of outcome constraints\nthat place restrictions on how other metrics can be moved by the experiment."}),"\n",(0,r.jsx)(n.p,{children:"In order to define an objective or outcome constraint, we first need to subclass Metric.\nMetrics are used to evaluate trials, which are individual steps of the experiment\nsequence. Each trial contains one or more arms for which we will collect data at the\nsame time."}),"\n",(0,r.jsx)(n.p,{children:"Our custom metric(s) will determine how, given a trial, to compute the mean and SEM of\neach of the trial's arms."}),"\n",(0,r.jsxs)(n.p,{children:["The only method that needs to be defined for most metric subclasses is\n",(0,r.jsx)(n.code,{children:"fetch_trial_data"}),", which defines how a single trial is evaluated, and returns a pandas\ndataframe."]}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"is_available_while_running"})," method is optional and returns a boolean, specifying\nwhether the trial data can be fetched before the trial is complete. See\n",(0,r.jsx)(n.a,{href:"6.-Inspect-trials'-data",children:"6. Inspect trials' data"})," for more details."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from ax import Data\nimport pandas as pd\n\n\nclass BoothMetric(Metric):\n    def fetch_trial_data(self, trial):\n        records = []\n        for arm_name, arm in trial.arms_by_name.items():\n            params = arm.parameters\n            records.append(\n                {\n                    "arm_name": arm_name,\n                    "metric_name": self.name,\n                    "trial_index": trial.index,\n                    # in practice, the mean and sem will be looked up based on trial metadata\n                    # but for this tutorial we will calculate them\n                    "mean": (params["x1"] + 2 * params["x2"] - 7) ** 2\n                    + (2 * params["x1"] + params["x2"] - 5) ** 2,\n                    "sem": 0.0,\n                }\n            )\n        return Data(df=pd.DataFrame.from_records(records))\n\n    def is_available_while_running(self) -> bool:\n        return True\n'})}),"\n",(0,r.jsx)(n.h2,{id:"9-save-to-json-or-sql",children:"9. Save to JSON or SQL"}),"\n",(0,r.jsx)(n.p,{children:"At any point, we can also save our experiment to a JSON file. To ensure that our custom\nmetrics and runner are saved properly, we first need to register them."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from ax.storage.registry_bundle import RegistryBundle\n\nbundle = RegistryBundle(\n    metric_clss={BoothMetric: None, L2NormMetric: None, Hartmann6Metric: None},\n    runner_clss={MyRunner: None},\n)\n\nfrom ax.storage.json_store.load import load_experiment\nfrom ax.storage.json_store.save import save_experiment\n\nsave_experiment(exp, "experiment.json", encoder_registry=bundle.encoder_registry)\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'loaded_experiment = load_experiment(\n    "experiment.json", decoder_registry=bundle.decoder_registry\n)\n'})}),"\n",(0,r.jsx)(n.p,{children:"To save our experiment to SQL, we must first specify a connection to a database and\ncreate all necessary tables."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from ax.storage.sqa_store.db import (\n    init_engine_and_session_factory,\n    get_engine,\n    create_all_tables,\n)\nfrom ax.storage.sqa_store.load import load_experiment\nfrom ax.storage.sqa_store.save import save_experiment\n\ninit_engine_and_session_factory(url="sqlite:///foo3.db")\n\nengine = get_engine()\ncreate_all_tables(engine)\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from ax.storage.sqa_store.sqa_config import SQAConfig\n\nexp.name = "new"\n\nsqa_config = SQAConfig(\n    json_encoder_registry=bundle.encoder_registry,\n    json_decoder_registry=bundle.decoder_registry,\n    metric_registry=bundle.metric_registry,\n    runner_registry=bundle.runner_registry,\n)\n\nsave_experiment(exp, config=sqa_config)\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"load_experiment(exp.name, config=sqa_config)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}},1023:(e,n,t)=>{t.d(n,{A:()=>h});t(6540);var r,a=new Uint8Array(16);function i(){if(!r&&!(r="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return r(a)}const o=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;const s=function(e){return"string"==typeof e&&o.test(e)};for(var l=[],c=0;c<256;++c)l.push((c+256).toString(16).substr(1));const d=function(e){var n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,t=(l[e[n+0]]+l[e[n+1]]+l[e[n+2]]+l[e[n+3]]+"-"+l[e[n+4]]+l[e[n+5]]+"-"+l[e[n+6]]+l[e[n+7]]+"-"+l[e[n+8]]+l[e[n+9]]+"-"+l[e[n+10]]+l[e[n+11]]+l[e[n+12]]+l[e[n+13]]+l[e[n+14]]+l[e[n+15]]).toLowerCase();if(!s(t))throw TypeError("Stringified UUID is invalid");return t};const m=function(e,n,t){var r=(e=e||{}).random||(e.rng||i)();if(r[6]=15&r[6]|64,r[8]=63&r[8]|128,n){t=t||0;for(var a=0;a<16;++a)n[t+a]=r[a];return n}return d(r)};var p=t(4848);const h=function(e){return(0,p.jsxs)("div",{style:{backgroundColor:"lightgray",marginBottom:"var(--ifm-leading)",borderRadius:"var(--ifm-global-radius)",boxShadow:"var(--ifm-global-shadow-lw)",overflow:"hidden",padding:"10px",font:"var(--ifm-code-font-size) / var(--ifm-pre-line-height) var(--ifm-font-family-monospace)"},children:[(0,p.jsx)("span",{style:{color:"red"},children:"Out: "}),(0,p.jsx)("pre",{style:{margin:"0px",backgroundColor:"inherit"},children:e.children.split("\n").map((function(e){return(0,p.jsx)("p",{style:{marginBottom:"0px"},children:e},m())}))})]})}},8987:(e,n,t)=>{t.d(n,{A:()=>i});t(6540);var r=t(8774),a=t(4848);const i=function(e){var n=e.githubUrl,t=e.colabUrl;return(0,a.jsxs)("div",{className:"link-buttons",children:[(0,a.jsx)(r.A,{to:n,children:"Open in GitHub"}),(0,a.jsx)("div",{}),(0,a.jsx)(r.A,{to:t,children:"Run in Google Colab"})]})}},290:(e,n,t)=>{t(6540);var r=t(3259),a=t.n(r),i=(t(2303),t(4848));a()({loader:function(){return t.e(236).then(t.bind(t,1236))},loading:function(e){return e.timedOut?(0,i.jsx)("blockquote",{children:"Error: Loading Plotly timed out."}):(0,i.jsx)("div",{children:"loading..."})},timeout:1e4})},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var r=t(6540);const a={},i=r.createContext(a);function o(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);