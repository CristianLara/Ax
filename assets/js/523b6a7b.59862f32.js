"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[809],{1771:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var i=t(4848),a=t(8453),r=t(8987);t(1023),t(290);const o={title:"Sparsity Exploration Bayesian Optimization (SEBO)",sidebar_label:"Sparsity Exploration Bayesian Optimization (SEBO)"},s="Sparsity Exploration Bayesian Optimization (SEBO) Ax API",l={id:"tutorials/sebo/index",title:"Sparsity Exploration Bayesian Optimization (SEBO)",description:"<LinkButtons",source:"@site/../docs/tutorials/sebo/index.mdx",sourceDirName:"tutorials/sebo",slug:"/tutorials/sebo/",permalink:"/Ax/docs/tutorials/sebo/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"Sparsity Exploration Bayesian Optimization (SEBO)",sidebar_label:"Sparsity Exploration Bayesian Optimization (SEBO)"},sidebar:"tutorials",previous:{title:"Fully Bayesian, High-Dimensional, Multi-Objective Optimization",permalink:"/Ax/docs/tutorials/saasbo_nehvi/"},next:{title:"Trial-Level Early Stopping",permalink:"/Ax/docs/tutorials/early_stopping/"}},c={},p=[{value:"Problem Setup",id:"problem-setup",level:2},{value:"Run optimization loop",id:"run-optimization-loop",level:2},{value:"Plot sparisty vs objective",id:"plot-sparisty-vs-objective",level:2},{value:"Create <code>GenerationStrategy</code>",id:"create-generationstrategy",level:2},{value:"Initialize client and set up experiment",id:"initialize-client-and-set-up-experiment",level:2},{value:"Define evaluation function",id:"define-evaluation-function",level:2},{value:"Run optimization loop",id:"run-optimization-loop-1",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.A,{githubUrl:"",colabUrl:""}),"\n",(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"sparsity-exploration-bayesian-optimization-sebo-ax-api",children:"Sparsity Exploration Bayesian Optimization (SEBO) Ax API"})}),"\n",(0,i.jsx)(n.p,{children:"This tutorial introduces the Sparsity Exploration Bayesian Optimization (SEBO) method\nand demonstrates how to utilize it using the Ax API. SEBO is designed to enhance\nBayesian Optimization (BO) by taking the interpretability and simplicity of\nconfigurations into consideration. In essence, SEBO incorporates sparsity, modeled as\nthe $L_0$ norm, as an additional objective in BO. By employing multi-objective\noptimization techniques such as Expected Hyper-Volume Improvement, SEBO enables the\njoint optimization of objectives while simultaneously incorporating feature-level\nsparsity. This allows users to efficiently explore different trade-offs between\nobjectives and sparsity."}),"\n",(0,i.jsx)(n.p,{children:"For a more detailed understanding of the SEBO algorithm, please refer to the following\npublication:"}),"\n",(0,i.jsxs)(n.p,{children:["[1]\n",(0,i.jsx)(n.a,{href:"https://proceedings.mlr.press/v206/liu23b/liu23b.pdf",children:"S. Liu, Q. Feng, D. Eriksson, B. Letham and E. Bakshy. Sparse Bayesian Optimization. International Conference on Artificial Intelligence and Statistics, 2023."})]}),"\n",(0,i.jsx)(n.p,{children:"By following this tutorial, you will learn how to leverage the SEBO method through the\nAx API, empowering you to effectively balance objectives and sparsity in your\noptimization tasks. Let's get started!"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import math\nimport os\nimport warnings\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport torch\nfrom ax import Data, Experiment, ParameterType, RangeParameter, SearchSpace\nfrom ax.core.objective import Objective\nfrom ax.core.optimization_config import OptimizationConfig\nfrom ax.metrics.noisy_function import NoisyFunctionMetric\nfrom ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\nfrom ax.modelbridge.registry import Models\nfrom ax.models.torch.botorch_modular.sebo import SEBOAcquisition\nfrom ax.models.torch.botorch_modular.surrogate import Surrogate\nfrom ax.runners.synthetic import SyntheticRunner\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\nfrom ax.utils.common.typeutils import checked_cast\nfrom botorch.acquisition.multi_objective import qNoisyExpectedHypervolumeImprovement\nfrom botorch.models import SaasFullyBayesianSingleTaskGP, SingleTaskGP\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'%matplotlib inline\nmatplotlib.rcParams.update({"font.size": 16})\n\nwarnings.filterwarnings(\'ignore\')\nSMOKE_TEST = os.environ.get("SMOKE_TEST")\n\ntorch.manual_seed(12345)  # To always get the same Sobol points\ntkwargs = {\n    "dtype": torch.double,\n    "device": torch.device("cuda" if torch.cuda.is_available() else "cpu"),\n}\n'})}),"\n",(0,i.jsx)(n.h1,{id:"demo-of-using-developer-api",children:"Demo of using Developer API"}),"\n",(0,i.jsx)(n.h2,{id:"problem-setup",children:"Problem Setup"}),"\n",(0,i.jsx)(n.p,{children:"In this simple experiment we use the Branin function embedded in a 10-dimensional space.\nAdditional resources:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["To set up a custom metric for your problem, refer to the dedicated section of the\nDeveloper API tutorial:\n",(0,i.jsx)(n.a,{href:"https://ax.dev/tutorials/gpei_hartmann_developer.html#8.-Defining-custom-metrics",children:"https://ax.dev/tutorials/gpei_hartmann_developer.html#8.-Defining-custom-metrics"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["To avoid needing to setup up custom metrics by Ax Service API:\n",(0,i.jsx)(n.a,{href:"https://ax.dev/tutorials/gpei_hartmann_service.html",children:"https://ax.dev/tutorials/gpei_hartmann_service.html"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"aug_dim = 8 \n\n# evaluation function \ndef branin_augment(x_vec, augment_dim):\n    assert len(x_vec) == augment_dim\n    x1, x2 = (\n        15 * x_vec[0] - 5,\n        15 * x_vec[1],\n    )  # Only dimensions 0 and augment_dim-1 affect the value of the function\n    t1 = x2 - 5.1 / (4 * math.pi**2) * x1**2 + 5 / math.pi * x1 - 6\n    t2 = 10 * (1 - 1 / (8 * math.pi)) * np.cos(x1)\n    return t1**2 + t2 + 10\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class AugBraninMetric(NoisyFunctionMetric):\n    def f(self, x: np.ndarray) -> float:\n        return checked_cast(float, branin_augment(x_vec=x, augment_dim=aug_dim))\n\n\n# Create search space in Ax \nsearch_space = SearchSpace(\n    parameters=[\n        RangeParameter(\n            name=f"x{i}",\n            parameter_type=ParameterType.FLOAT, \n            lower=0.0, upper=1.0\n        )\n        for i in range(aug_dim)\n    ]\n)\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Create optimization goals \noptimization_config = OptimizationConfig(\n    objective=Objective(\n        metric=AugBraninMetric(\n            name="objective",\n            param_names=[f"x{i}" for i in range(aug_dim)],\n            noise_sd=None,  # Set noise_sd=None if you want to learn the noise, otherwise it defaults to 1e-6\n        ),\n        minimize=True,\n    )\n)\n\n# Experiment\nexperiment = Experiment(\n    name="sebo_experiment",\n    search_space=search_space,\n    optimization_config=optimization_config,\n    runner=SyntheticRunner(),\n)\n\n# target sparse point to regularize towards to. Here we set target sparse value being zero for all the parameters. \ntarget_point = torch.tensor([0 for _ in range(aug_dim)], **tkwargs)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"run-optimization-loop",children:"Run optimization loop"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'N_INIT = 10\n\nif SMOKE_TEST:\n    N_BATCHES = 1\n    BATCH_SIZE = 1\n    SURROGATE_CLASS = None  # Auto-pick SingleTaskGP\nelse:\n    N_BATCHES = 4\n    BATCH_SIZE = 5\n    SURROGATE_CLASS = SaasFullyBayesianSingleTaskGP\n\nprint(f"Doing {N_INIT + N_BATCHES * BATCH_SIZE} evaluations")\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Initial Sobol points\nsobol = Models.SOBOL(search_space=experiment.search_space)\nfor _ in range(N_INIT):\n    experiment.new_trial(sobol.gen(1)).run()\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'data = experiment.fetch_data()\n\nfor i in range(N_BATCHES):\n\n    model = Models.BOTORCH_MODULAR(\n        experiment=experiment, \n        data=data,\n        surrogate=Surrogate(botorch_model_class=SURROGATE_CLASS),  # can use SAASGP (i.e. SaasFullyBayesianSingleTaskGP) for high-dim cases\n        search_space=experiment.search_space,\n        botorch_acqf_class=qNoisyExpectedHypervolumeImprovement,\n        acquisition_class=SEBOAcquisition,\n        acquisition_options={\n            "penalty": "L0_norm", # it can be L0_norm or L1_norm. \n            "target_point": target_point, \n            "sparsity_threshold": aug_dim,\n        },\n        torch_device=tkwargs[\'device\'],\n    )\n\n    generator_run = model.gen(BATCH_SIZE)\n    trial = experiment.new_batch_trial(generator_run=generator_run)\n    trial.run()\n\n    new_data = trial.fetch_data(metrics=list(experiment.metrics.values()))\n    data = Data.from_multiple_data([data, new_data])\n    print(f"Iteration: {i}, Best so far: {data.df[\'mean\'].min():.3f}")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"plot-sparisty-vs-objective",children:"Plot sparisty vs objective"}),"\n",(0,i.jsx)(n.p,{children:"Visualize the objective and sparsity trade-offs using SEBO. Each point represent designs\nalong the Pareto frontier found by SEBO. The x-axis corresponds to the number of active\nparameters used, i.e. non-sparse parameters, and the y-axis corresponds the best\nidentified objective values. Based on this, decision-makers balance both\nsimplicity/interpretability of generated policies and optimization performance when\ndeciding which configuration to use."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def nnz_exact(x, sparse_point):\n    return len(x) - (np.array(x) == np.array(sparse_point)).sum()\n\n    \ndf = data.df\ndf['L0_norm'] = df['arm_name'].apply(lambda d: nnz_exact(list(experiment.arms_by_name[d].parameters.values()), [0 for _ in range(aug_dim)]) )\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"result_by_sparsity = {l: df[df.L0_norm <= l]['mean'].min() for l in range(1, aug_dim+1)}\nresult_by_sparsity\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'fig, ax = plt.subplots(figsize=(8, 6))\nax.plot(list(result_by_sparsity.keys()), list(result_by_sparsity.values()), \'.b-\', label="sebo", markersize=10)\nax.grid(True)\nax.set_title(f"Branin, D={aug_dim}", fontsize=20)\nax.set_xlabel("Number of active parameters", fontsize=20)\nax.set_ylabel("Best value found", fontsize=20)\n# ax.legend(fontsize=18)\nplt.show()\n'})}),"\n",(0,i.jsx)(n.h1,{id:"demo-of-using-generationstrategy-and-service-api",children:"Demo of Using GenerationStrategy and Service API"}),"\n",(0,i.jsxs)(n.p,{children:["Please check ",(0,i.jsx)(n.a,{href:"https://ax.dev/tutorials/gpei_hartmann_service.html",children:"Service API tutorial"}),"\nfor more detailed information."]}),"\n",(0,i.jsxs)(n.h2,{id:"create-generationstrategy",children:["Create ",(0,i.jsx)(n.code,{children:"GenerationStrategy"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'gs = GenerationStrategy(\n    name="SEBO_L0",\n    steps=[\n        GenerationStep(  # Initialization step\n            model=Models.SOBOL,     \n            num_trials=N_INIT,\n        ),\n        GenerationStep(  # BayesOpt step\n            model=Models.BOTORCH_MODULAR,\n            # No limit on how many generator runs will be produced\n            num_trials=-1,\n            model_kwargs={  # Kwargs to pass to `BoTorchModel.__init__`\n                "surrogate": Surrogate(botorch_model_class=SURROGATE_CLASS),\n                "acquisition_class": SEBOAcquisition,\n                "botorch_acqf_class": qNoisyExpectedHypervolumeImprovement,\n                "acquisition_options": {\n                    "penalty": "L0_norm", # it can be L0_norm or L1_norm.\n                    "target_point": target_point, \n                    "sparsity_threshold": aug_dim,\n                },\n            },\n        )\n    ]\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"initialize-client-and-set-up-experiment",children:"Initialize client and set up experiment"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'ax_client = AxClient(generation_strategy=gs)\n\nexperiment_parameters = [\n    {\n        "name": f"x{i}",\n        "type": "range",\n        "bounds": [0, 1],\n        "value_type": "float",\n        "log_scale": False,\n    }\n    for i in range(aug_dim)\n]\n\nobjective_metrics = {\n    "objective": ObjectiveProperties(minimize=False, threshold=-10),\n}\n\nax_client.create_experiment(\n    name="branin_augment_sebo_experiment",\n    parameters=experiment_parameters,\n    objectives=objective_metrics,\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"define-evaluation-function",children:"Define evaluation function"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def evaluation(parameters):\n    # put parameters into 1-D array\n    x = [parameters.get(param["name"]) for param in experiment_parameters]\n    res = branin_augment(x_vec=x, augment_dim=aug_dim)\n    eval_res = {\n        # flip the sign to maximize\n        "objective": (res * -1, 0.0),\n    }\n    return eval_res\n'})}),"\n",(0,i.jsx)(n.h2,{id:"run-optimization-loop-1",children:"Run optimization loop"}),"\n",(0,i.jsx)(n.p,{children:"Running only 1 BO trial for demonstration."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"for _ in range(N_INIT + 1):    \n    parameters, trial_index = ax_client.get_next_trial()\n    res = evaluation(parameters)\n    ax_client.complete_trial(trial_index=trial_index, raw_data=res)\n"})})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},1023:(e,n,t)=>{t.d(n,{A:()=>u});t(6540);var i,a=new Uint8Array(16);function r(){if(!i&&!(i="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return i(a)}const o=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;const s=function(e){return"string"==typeof e&&o.test(e)};for(var l=[],c=0;c<256;++c)l.push((c+256).toString(16).substr(1));const p=function(e){var n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,t=(l[e[n+0]]+l[e[n+1]]+l[e[n+2]]+l[e[n+3]]+"-"+l[e[n+4]]+l[e[n+5]]+"-"+l[e[n+6]]+l[e[n+7]]+"-"+l[e[n+8]]+l[e[n+9]]+"-"+l[e[n+10]]+l[e[n+11]]+l[e[n+12]]+l[e[n+13]]+l[e[n+14]]+l[e[n+15]]).toLowerCase();if(!s(t))throw TypeError("Stringified UUID is invalid");return t};const d=function(e,n,t){var i=(e=e||{}).random||(e.rng||r)();if(i[6]=15&i[6]|64,i[8]=63&i[8]|128,n){t=t||0;for(var a=0;a<16;++a)n[t+a]=i[a];return n}return p(i)};var m=t(4848);const u=function(e){return(0,m.jsxs)("div",{style:{backgroundColor:"lightgray",marginBottom:"var(--ifm-leading)",borderRadius:"var(--ifm-global-radius)",boxShadow:"var(--ifm-global-shadow-lw)",overflow:"hidden",padding:"10px",font:"var(--ifm-code-font-size) / var(--ifm-pre-line-height) var(--ifm-font-family-monospace)"},children:[(0,m.jsx)("span",{style:{color:"red"},children:"Out: "}),(0,m.jsx)("pre",{style:{margin:"0px",backgroundColor:"inherit"},children:e.children.split("\n").map((function(e){return(0,m.jsx)("p",{style:{marginBottom:"0px"},children:e},d())}))})]})}},8987:(e,n,t)=>{t.d(n,{A:()=>r});t(6540);var i=t(8774),a=t(4848);const r=function(e){var n=e.githubUrl,t=e.colabUrl;return(0,a.jsxs)("div",{className:"link-buttons",children:[(0,a.jsx)(i.A,{to:n,children:"Open in GitHub"}),(0,a.jsx)("div",{}),(0,a.jsx)(i.A,{to:t,children:"Run in Google Colab"})]})}},290:(e,n,t)=>{t(6540);var i=t(3259),a=t.n(i),r=(t(2303),t(4848));a()({loader:function(){return t.e(236).then(t.bind(t,1236))},loading:function(e){return e.timedOut?(0,r.jsx)("blockquote",{children:"Error: Loading Plotly timed out."}):(0,r.jsx)("div",{children:"loading..."})},timeout:1e4})},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var i=t(6540);const a={},r=i.createContext(a);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);