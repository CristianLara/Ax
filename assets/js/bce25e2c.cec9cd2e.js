"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[916],{8167:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>l,toc:()=>m});var r=t(4848),a=t(8453),i=t(8987);t(1023),t(290);const o={title:"RandomForest with ExternalGenerationNode",sidebar_label:"RandomForest with ExternalGenerationNode"},s="Using external methods for candidate generation in Ax",l={id:"tutorials/external_generation_node/index",title:"RandomForest with ExternalGenerationNode",description:"<LinkButtons",source:"@site/../docs/tutorials/external_generation_node/index.mdx",sourceDirName:"tutorials/external_generation_node",slug:"/tutorials/external_generation_node/",permalink:"/Ax/docs/tutorials/external_generation_node/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"RandomForest with ExternalGenerationNode",sidebar_label:"RandomForest with ExternalGenerationNode"},sidebar:"tutorials",previous:{title:"Human-in-the-Loop Optimization",permalink:"/Ax/docs/tutorials/human_in_the_loop/"}},d={},m=[{value:"Construct the GenerationStrategy",id:"construct-the-generationstrategy",level:2},{value:"Run a simple experiment using AxClient",id:"run-a-simple-experiment-using-axclient",level:2},{value:"Run the optimization loop",id:"run-the-optimization-loop",level:3},{value:"View the trials generated during optimization",id:"view-the-trials-generated-during-optimization",level:3}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.A,{githubUrl:"",colabUrl:""}),"\n",(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"using-external-methods-for-candidate-generation-in-ax",children:"Using external methods for candidate generation in Ax"})}),"\n",(0,r.jsxs)(n.p,{children:["Out of the box, Ax offers many options for candidate generation, most of which utilize\nBayesian optimization algorithms built using ",(0,r.jsx)(n.a,{href:"https://botorch.org/",children:"BoTorch"}),". For users\nthat want to leverage Ax for experiment orchestration (via ",(0,r.jsx)(n.code,{children:"AxClient"})," or ",(0,r.jsx)(n.code,{children:"Scheduler"}),")\nand other features (e.g., early stopping), while relying on other methods for candidate\ngeneration, we introduced ",(0,r.jsx)(n.code,{children:"ExternalGenerationNode"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.code,{children:"GenerationNode"})," is a building block of a ",(0,r.jsx)(n.code,{children:"GenerationStrategy"}),". They can be combined\ntogether utilize different methods for generating candidates at different stages of an\nexperiment. ",(0,r.jsx)(n.code,{children:"ExternalGenerationNode"})," exposes a lightweight interface to allow the users\nto easily integrate their methods into Ax, and use them as standalone or with other\n",(0,r.jsx)(n.code,{children:"GenerationNode"}),"s in a ",(0,r.jsx)(n.code,{children:"GenerationStrategy"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["In this tutorial, we will implement a simple generation node using\n",(0,r.jsx)(n.code,{children:"RandomForestRegressor"})," from sklearn, and combine it with Sobol (for initialization) to\noptimize the Hartmann6 problem."]}),"\n",(0,r.jsx)(n.p,{children:"NOTE: This is for illustration purposes only. We do not recommend using this strategy as\nit typically does not perform well compared to Ax's default algorithms due to it's\noverly greedy behavior."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import time\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport numpy as np\nfrom ax.core.base_trial import TrialStatus\nfrom ax.core.data import Data\nfrom ax.core.experiment import Experiment\nfrom ax.core.parameter import RangeParameter\nfrom ax.core.types import TParameterization\nfrom ax.modelbridge.external_generation_node import ExternalGenerationNode\nfrom ax.modelbridge.generation_node import GenerationNode\nfrom ax.modelbridge.generation_strategy import GenerationStrategy\nfrom ax.modelbridge.model_spec import ModelSpec\nfrom ax.modelbridge.registry import Models\nfrom ax.modelbridge.transition_criterion import MaxTrials\nfrom ax.plot.trace import plot_objective_value_vs_trial_index\nfrom ax.service.ax_client import AxClient, ObjectiveProperties\nfrom ax.service.utils.report_utils import exp_to_df\nfrom ax.utils.common.typeutils import checked_cast\nfrom ax.utils.measurement.synthetic_functions import hartmann6\nfrom sklearn.ensemble import RandomForestRegressor\n\n\nclass RandomForestGenerationNode(ExternalGenerationNode):\n    """A generation node that uses the RandomForestRegressor\n    from sklearn to predict candidate performance and picks the\n    next point as the random sample that has the best prediction.\n\n    To leverage external methods for candidate generation, the user must\n    create a subclass that implements ``update_generator_state`` and\n    ``get_next_candidate`` methods. This can then be provided\n    as a node into a ``GenerationStrategy``, either as standalone or as\n    part of a larger generation strategy with other generation nodes,\n    e.g., with a Sobol node for initialization.\n    """\n\n    def __init__(self, num_samples: int, regressor_options: Dict[str, Any]) -> None:\n        """Initialize the generation node.\n\n        Args:\n            regressor_options: Options to pass to the random forest regressor.\n            num_samples: Number of random samples from the search space\n                used during candidate generation. The sample with the best\n                prediction is recommended as the next candidate.\n        """\n        t_init_start = time.monotonic()\n        super().__init__(node_name="RandomForest")\n        self.num_samples: int = num_samples\n        self.regressor: RandomForestRegressor = RandomForestRegressor(\n            **regressor_options\n        )\n        # We will set these later when updating the state.\n        # Alternatively, we could have required experiment as an input\n        # and extracted them here.\n        self.parameters: Optional[List[RangeParameter]] = None\n        self.minimize: Optional[bool] = None\n        # Recording time spent in initializing the generator. This is\n        # used to compute the time spent in candidate generation.\n        self.fit_time_since_gen: float = time.monotonic() - t_init_start\n\n    def update_generator_state(self, experiment: Experiment, data: Data) -> None:\n        """A method used to update the state of the generator. This includes any\n        models, predictors or any other custom state used by the generation node.\n        This method will be called with the up-to-date experiment and data before\n        ``get_next_candidate`` is called to generate the next trial(s). Note\n        that ``get_next_candidate`` may be called multiple times (to generate\n        multiple candidates) after a call to  ``update_generator_state``.\n\n        For this example, we will train the regressor using the latest data from\n        the experiment.\n\n        Args:\n            experiment: The ``Experiment`` object representing the current state of the\n                experiment. The key properties includes ``trials``, ``search_space``,\n                and ``optimization_config``. The data is provided as a separate arg.\n            data: The data / metrics collected on the experiment so far.\n        """\n        search_space = experiment.search_space\n        parameter_names = list(search_space.parameters.keys())\n        metric_names = list(experiment.optimization_config.metrics.keys())\n        if any(\n            not isinstance(p, RangeParameter) for p in search_space.parameters.values()\n        ):\n            raise NotImplementedError(\n                "This example only supports RangeParameters in the search space."\n            )\n        if search_space.parameter_constraints:\n            raise NotImplementedError(\n                "This example does not support parameter constraints."\n            )\n        if len(metric_names) != 1:\n            raise NotImplementedError(\n                "This example only supports single-objective optimization."\n            )\n        # Get the data for the completed trials.\n        num_completed_trials = len(experiment.trials_by_status[TrialStatus.COMPLETED])\n        x = np.zeros([num_completed_trials, len(parameter_names)])\n        y = np.zeros([num_completed_trials, 1])\n        for t_idx, trial in experiment.trials.items():\n            if trial.status == "COMPLETED":\n                trial_parameters = trial.arm.parameters\n                x[t_idx, :] = np.array([trial_parameters[p] for p in parameter_names])\n                trial_df = data.df[data.df["trial_index"] == t_idx]\n                y[t_idx, 0] = trial_df[trial_df["metric_name"] == metric_names[0]][\n                    "mean"\n                ].item()\n\n        # Train the regressor.\n        self.regressor.fit(x, y)\n        # Update the attributes not set in __init__.\n        self.parameters = search_space.parameters\n        self.minimize = experiment.optimization_config.objective.minimize\n\n    def get_next_candidate(\n        self, pending_parameters: List[TParameterization]\n    ) -> TParameterization:\n        """Get the parameters for the next candidate configuration to evaluate.\n\n        We will draw ``self.num_samples`` random samples from the search space\n        and predict the objective value for each sample. We will then return\n        the sample with the best predicted value.\n\n        Args:\n            pending_parameters: A list of parameters of the candidates pending\n                evaluation. This is often used to avoid generating duplicate candidates.\n                We ignore this here for simplicity.\n\n        Returns:\n            A dictionary mapping parameter names to parameter values for the next\n            candidate suggested by the method.\n        """\n        bounds = np.array([[p.lower, p.upper] for p in self.parameters.values()])\n        unit_samples = np.random.random_sample([self.num_samples, len(bounds)])\n        samples = bounds[:, 0] + (bounds[:, 1] - bounds[:, 0]) * unit_samples\n        # Predict the objective value for each sample.\n        y_pred = self.regressor.predict(samples)\n        # Find the best sample.\n        best_idx = np.argmin(y_pred) if self.minimize else np.argmax(y_pred)\n        best_sample = samples[best_idx, :]\n        # Convert the sample to a parameterization.\n        candidate = {\n            p_name: best_sample[i].item()\n            for i, p_name in enumerate(self.parameters.keys())\n        }\n        return candidate\n'})}),"\n",(0,r.jsx)(n.h2,{id:"construct-the-generationstrategy",children:"Construct the GenerationStrategy"}),"\n",(0,r.jsx)(n.p,{children:"We will use Sobol for the first 5 trials and defer to random forest for the rest."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'generation_strategy = GenerationStrategy(\n    name="Sobol+RandomForest",\n    nodes=[\n        GenerationNode(\n            node_name="Sobol",\n            model_specs=[ModelSpec(Models.SOBOL)],\n            transition_criteria=[\n                MaxTrials(\n                    # This specifies the maximum number of trials to generate from this node, \n                    # and the next node in the strategy.\n                    threshold=5,\n                    block_transition_if_unmet=True,\n                    transition_to="RandomForest"\n                )\n            ],\n        ),\n        RandomForestGenerationNode(num_samples=128, regressor_options={}),\n    ],\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"run-a-simple-experiment-using-axclient",children:"Run a simple experiment using AxClient"}),"\n",(0,r.jsxs)(n.p,{children:["More details on how to use AxClient can be found in the\n",(0,r.jsx)(n.a,{href:"https://ax.dev/tutorials/gpei_hartmann_service.html",children:"tutorial"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'ax_client = AxClient(generation_strategy=generation_strategy)\n\nax_client.create_experiment(\n    name="hartmann_test_experiment",\n    parameters=[\n        {\n            "name": f"x{i}",\n            "type": "range",\n            "bounds": [0.0, 1.0],\n            "value_type": "float",  # Optional, defaults to inference from type of "bounds".\n        }\n        for i in range(1, 7)\n    ],\n    objectives={"hartmann6": ObjectiveProperties(minimize=True)},\n)\n\n\ndef evaluate(parameterization: TParameterization) -> Dict[str, Tuple[float, float]]:\n    x = np.array([parameterization.get(f"x{i+1}") for i in range(6)])\n    return {"hartmann6": (checked_cast(float, hartmann6(x)), 0.0)}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"run-the-optimization-loop",children:"Run the optimization loop"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"for i in range(15):\n    parameterization, trial_index = ax_client.get_next_trial()\n    ax_client.complete_trial(\n        trial_index=trial_index, raw_data=evaluate(parameterization)\n    )\n"})}),"\n",(0,r.jsx)(n.h3,{id:"view-the-trials-generated-during-optimization",children:"View the trials generated during optimization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"exp_df = exp_to_df(ax_client.experiment)\nexp_df\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'plot_objective_value_vs_trial_index(\n    exp_df=exp_df,\n    metric_colname="hartmann6",\n    minimize=True,\n    title="Hartmann6 Objective Value vs. Trial Index",\n)\n'})})]})}function c(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},1023:(e,n,t)=>{t.d(n,{A:()=>h});t(6540);var r,a=new Uint8Array(16);function i(){if(!r&&!(r="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return r(a)}const o=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;const s=function(e){return"string"==typeof e&&o.test(e)};for(var l=[],d=0;d<256;++d)l.push((d+256).toString(16).substr(1));const m=function(e){var n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,t=(l[e[n+0]]+l[e[n+1]]+l[e[n+2]]+l[e[n+3]]+"-"+l[e[n+4]]+l[e[n+5]]+"-"+l[e[n+6]]+l[e[n+7]]+"-"+l[e[n+8]]+l[e[n+9]]+"-"+l[e[n+10]]+l[e[n+11]]+l[e[n+12]]+l[e[n+13]]+l[e[n+14]]+l[e[n+15]]).toLowerCase();if(!s(t))throw TypeError("Stringified UUID is invalid");return t};const p=function(e,n,t){var r=(e=e||{}).random||(e.rng||i)();if(r[6]=15&r[6]|64,r[8]=63&r[8]|128,n){t=t||0;for(var a=0;a<16;++a)n[t+a]=r[a];return n}return m(r)};var c=t(4848);const h=function(e){return(0,c.jsxs)("div",{style:{backgroundColor:"lightgray",marginBottom:"var(--ifm-leading)",borderRadius:"var(--ifm-global-radius)",boxShadow:"var(--ifm-global-shadow-lw)",overflow:"hidden",padding:"10px",font:"var(--ifm-code-font-size) / var(--ifm-pre-line-height) var(--ifm-font-family-monospace)"},children:[(0,c.jsx)("span",{style:{color:"red"},children:"Out: "}),(0,c.jsx)("pre",{style:{margin:"0px",backgroundColor:"inherit"},children:e.children.split("\n").map((function(e){return(0,c.jsx)("p",{style:{marginBottom:"0px"},children:e},p())}))})]})}},8987:(e,n,t)=>{t.d(n,{A:()=>i});t(6540);var r=t(8774),a=t(4848);const i=function(e){var n=e.githubUrl,t=e.colabUrl;return(0,a.jsxs)("div",{className:"link-buttons",children:[(0,a.jsx)(r.A,{to:n,children:"Open in GitHub"}),(0,a.jsx)("div",{}),(0,a.jsx)(r.A,{to:t,children:"Run in Google Colab"})]})}},290:(e,n,t)=>{t(6540);var r=t(3259),a=t.n(r),i=(t(2303),t(4848));a()({loader:function(){return t.e(236).then(t.bind(t,1236))},loading:function(e){return e.timedOut?(0,i.jsx)("blockquote",{children:"Error: Loading Plotly timed out."}):(0,i.jsx)("div",{children:"loading..."})},timeout:1e4})},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var r=t(6540);const a={},i=r.createContext(a);function o(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);