"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[593],{3906:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var i=n(4848),r=n(8453),a=n(8987);n(1023),n(290);const o={title:"Trial-Level Early Stopping",sidebar_label:"Trial-Level Early Stopping"},s=void 0,l={id:"tutorials/early_stopping/index",title:"Trial-Level Early Stopping",description:"<LinkButtons",source:"@site/../docs/tutorials/early_stopping/index.mdx",sourceDirName:"tutorials/early_stopping",slug:"/tutorials/early_stopping/",permalink:"/Ax/docs/tutorials/early_stopping/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"Trial-Level Early Stopping",sidebar_label:"Trial-Level Early Stopping"},sidebar:"tutorials",previous:{title:"Sparsity Exploration Bayesian Optimization (SEBO)",permalink:"/Ax/docs/tutorials/sebo/"},next:{title:"Global Stopping (Experiment-Level Early Stopping)",permalink:"/Ax/docs/tutorials/gss/"}},p={},c=[{value:"Trial-level early stopping in Ax",id:"trial-level-early-stopping-in-ax",level:2},{value:"Defining the TorchX App",id:"defining-the-torchx-app",level:2},{value:"Setting up the Runner",id:"setting-up-the-runner",level:2},{value:"Setting up the SearchSpace",id:"setting-up-the-searchspace",level:2},{value:"Setting up Metrics",id:"setting-up-metrics",level:2},{value:"Setting up the OptimizationConfig",id:"setting-up-the-optimizationconfig",level:2},{value:"Defining an Early Stopping Strategy",id:"defining-an-early-stopping-strategy",level:2},{value:"Creating the Ax Experiment",id:"creating-the-ax-experiment",level:2},{value:"Choosing the GenerationStrategy",id:"choosing-the-generationstrategy",level:2},{value:"Configuring the Scheduler",id:"configuring-the-scheduler",level:2},{value:"Results",id:"results",level:2},{value:"Visualizations",id:"visualizations",level:2}];function d(e){const t={a:"a",code:"code",em:"em",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(a.A,{githubUrl:"",colabUrl:""}),"\n",(0,i.jsx)(t.h2,{id:"trial-level-early-stopping-in-ax",children:"Trial-level early stopping in Ax"}),"\n",(0,i.jsx)(t.p,{children:"This tutorial illustrates how to add a trial-level early stopping strategy to an Ax\nhyper-parameter optimization (HPO) loop. The goal of trial-level early stopping is to\nmonitor the results of expensive evaluations and terminate those that are unlikely to\nproduce promising results, freeing up resources to explore more configurations."}),"\n",(0,i.jsxs)(t.p,{children:["Most of this tutorial is adapted from the\n",(0,i.jsx)(t.a,{href:"https://pytorch.org/tutorials/intermediate/ax_multiobjective_nas_tutorial.html",children:"PyTorch Ax Multiobjective NAS Tutorial"}),".\nThe training job is different from the original in that we do not optimize ",(0,i.jsx)(t.code,{children:"batch_size"}),"\nor ",(0,i.jsx)(t.code,{children:"epochs"}),". This was done for illustrative purposes, as each validation curve now has\nthe same number of points. The companion training file ",(0,i.jsx)(t.code,{children:"mnist_train_nas.py"})," has also\nbeen altered to log to Tensorboard during training."]}),"\n",(0,i.jsxs)(t.p,{children:['NOTE: Although the original NAS tutorial is for a multi-objective problem, this tutorial\nfocuses on a single objective (validation accuracy) problem. Early stopping currently\ndoes not support "true" multi-objective stopping, although one can use\n',(0,i.jsx)(t.a,{href:"https://github.com/facebook/Ax/blob/main/ax/early_stopping/strategies/logical.py",children:"logical compositions of early stopping strategies"}),"\nto target multiple objectives separately. Early stopping for the multi-objective case is\ncurrently a work in progress."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"import os\nimport tempfile\n\nfrom pathlib import Path\n\nimport torchx\n\nfrom ax.core import Experiment, Objective, ParameterType, RangeParameter, SearchSpace\nfrom ax.core.optimization_config import OptimizationConfig\n\nfrom ax.early_stopping.strategies import PercentileEarlyStoppingStrategy\nfrom ax.metrics.tensorboard import TensorboardMetric\n\nfrom ax.modelbridge.dispatch_utils import choose_generation_strategy\n\nfrom ax.runners.torchx import TorchXRunner\n\nfrom ax.service.scheduler import Scheduler, SchedulerOptions\nfrom ax.service.utils.report_utils import exp_to_df\n\nfrom tensorboard.backend.event_processing import plugin_event_multiplexer as event_multiplexer\n\nfrom torchx import specs\nfrom torchx.components import utils\n\nfrom matplotlib import pyplot as plt\n\n\n%matplotlib inline\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'SMOKE_TEST = os.environ.get("SMOKE_TEST")\n'})}),"\n",(0,i.jsx)(t.h2,{id:"defining-the-torchx-app",children:"Defining the TorchX App"}),"\n",(0,i.jsxs)(t.p,{children:["Our goal is to optimize the PyTorch Lightning training job defined in\n",(0,i.jsx)(t.a,{href:"https://github.com/pytorch/tutorials/tree/master/intermediate_source/mnist_train_nas.py",children:"mnist_train_nas.py"}),(0,i.jsxs)(t.em,{children:[".\nTo do this using TorchX, we write a helper function that takes in the values of the\narchitcture and hyperparameters of the training job and creates a\n",(0,i.jsx)(t.a,{href:"https://pytorch.org/torchx/latest/basics.html",children:"TorchX AppDef"})]})," with the appropriate\nsettings."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"if SMOKE_TEST:\n    epochs = 3\nelse:\n    epochs = 10\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'def trainer(\n    log_path: str,\n    hidden_size_1: int,\n    hidden_size_2: int,\n    learning_rate: float,\n    dropout: float,\n    trial_idx: int = -1,\n) -> specs.AppDef:\n\n    # define the log path so we can pass it to the TorchX AppDef\n    if trial_idx >= 0:\n        log_path = Path(log_path).joinpath(str(trial_idx)).absolute().as_posix()\n\n    batch_size = 32\n\n    return utils.python(\n        # command line args to the training script\n        "--log_path",\n        log_path,\n        "--hidden_size_1",\n        str(hidden_size_1),\n        "--hidden_size_2",\n        str(hidden_size_2),\n        "--learning_rate",\n        str(learning_rate),\n        "--epochs",\n        str(epochs),\n        "--dropout",\n        str(dropout),\n        "--batch_size",\n        str(batch_size),\n        # other config options\n        name="trainer",\n        script="tutorials/early_stopping/mnist_train_nas.py",\n        image=torchx.version.TORCHX_IMAGE,\n    )\n'})}),"\n",(0,i.jsx)(t.h2,{id:"setting-up-the-runner",children:"Setting up the Runner"}),"\n",(0,i.jsxs)(t.p,{children:["Ax\u2019s ",(0,i.jsx)(t.a,{href:"https://ax.dev/api/core.html#ax.core.runner.Runner",children:"Runner"})," abstraction allows\nwriting interfaces to various backends. Ax already comes with Runner for TorchX, so we\njust need to configure it. For the purpose of this tutorial, we run jobs locally in a\nfully asynchronous fashion. In order to launch them on a cluster, you can instead\nspecify a different TorchX scheduler and adjust the configuration appropriately. For\nexample, if you have a Kubernetes cluster, you just need to change the scheduler from\n",(0,i.jsx)(t.code,{children:"local_cwd"})," to ",(0,i.jsx)(t.code,{children:"kubernetes"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["The training job launched by this runner will log partial results to Tensorboard, which\nwill then be monitored by the early stopping strategy. We will show how this is done\nusing an Ax\n",(0,i.jsx)(t.a,{href:"https://ax.dev/api/metrics.html#module-ax.metrics.tensorboard",children:"TensorboardMetric"}),"\nbelow."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'# Make a temporary dir to log our results into\nlog_dir = tempfile.mkdtemp()\n\nax_runner = TorchXRunner(\n    tracker_base="/tmp/",\n    component=trainer,\n    # NOTE: To launch this job on a cluster instead of locally you can\n    # specify a different scheduler and adjust args appropriately.\n    scheduler="local_cwd",\n    component_const_params={"log_path": log_dir},\n    cfg={},\n)\n'})}),"\n",(0,i.jsx)(t.h2,{id:"setting-up-the-searchspace",children:"Setting up the SearchSpace"}),"\n",(0,i.jsx)(t.p,{children:"First, we define our search space. Ax supports both range parameters of type integer and\nfloat as well as choice parameters which can have non-numerical types such as strings.\nWe will tune the hidden sizes, learning rate, and dropout parameters."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'parameters = [\n    # NOTE: In a real-world setting, hidden_size_1 and hidden_size_2\n    # should probably be powers of 2, but in our simple example this\n    # would mean that num_params can\'t take on that many values, which\n    # in turn makes the Pareto frontier look pretty weird.\n    RangeParameter(\n        name="hidden_size_1",\n        lower=16,\n        upper=128,\n        parameter_type=ParameterType.INT,\n        log_scale=True,\n    ),\n    RangeParameter(\n        name="hidden_size_2",\n        lower=16,\n        upper=128,\n        parameter_type=ParameterType.INT,\n        log_scale=True,\n    ),\n    RangeParameter(\n        name="learning_rate",\n        lower=1e-4,\n        upper=1e-2,\n        parameter_type=ParameterType.FLOAT,\n        log_scale=True,\n    ),\n    RangeParameter(\n        name="dropout",\n        lower=0.0,\n        upper=0.5,\n        parameter_type=ParameterType.FLOAT,\n    ),\n]\n\nsearch_space = SearchSpace(\n    parameters=parameters,\n    # NOTE: In practice, it may make sense to add a constraint\n    # hidden_size_2 <= hidden_size_1\n    parameter_constraints=[],\n)\n'})}),"\n",(0,i.jsx)(t.h2,{id:"setting-up-metrics",children:"Setting up Metrics"}),"\n",(0,i.jsx)(t.p,{children:"Ax has the concept of a Metric that defines properties of outcomes and how observations\nare obtained for these outcomes. This allows e.g. encodig how data is fetched from some\ndistributed execution backend and post-processed before being passed as input to Ax."}),"\n",(0,i.jsxs)(t.p,{children:["We will optimize the validation accuracy, which is a ",(0,i.jsx)(t.code,{children:"TensorboardMetric"})," that points to\nthe logging directory assigned above. Note that we have set\n",(0,i.jsx)(t.code,{children:"is_available_while_running"}),", allowing for the metric to be queried as the trial\nprogresses. This is critical for the early stopping strategy to monitor partial results."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"class MyTensorboardMetric(TensorboardMetric):\n\n    # NOTE: We need to tell the new Tensorboard metric how to get the id /\n    # file handle for the tensorboard logs from a trial. In this case\n    # our convention is to just save a separate file per trial in\n    # the pre-specified log dir.\n    def _get_event_multiplexer_for_trial(self, trial):\n        mul = event_multiplexer.EventMultiplexer(max_reload_threads=20)\n        mul.AddRunsFromDirectory(Path(log_dir).joinpath(str(trial.index)).as_posix(), None)\n        mul.Reload()\n\n        return mul\n\n    # This indicates whether the metric is queryable while the trial is\n    # still running. This is required for early stopping to monitor the\n    # progress of the running trial.ArithmeticError\n    @classmethod\n    def is_available_while_running(cls):\n        return True\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'val_acc = MyTensorboardMetric(\n    name="val_acc",\n    tag="val_acc",\n    lower_is_better=False,\n)\n'})}),"\n",(0,i.jsx)(t.h2,{id:"setting-up-the-optimizationconfig",children:"Setting up the OptimizationConfig"}),"\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.code,{children:"OptimizationConfig"})," specifies the objective for Ax to optimize."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"opt_config = OptimizationConfig(\n    objective=Objective(\n        metric=val_acc,\n        minimize=False,\n    )\n)\n"})}),"\n",(0,i.jsx)(t.h2,{id:"defining-an-early-stopping-strategy",children:"Defining an Early Stopping Strategy"}),"\n",(0,i.jsxs)(t.p,{children:["A ",(0,i.jsx)(t.code,{children:"PercentileEarlyStoppingStrategy"})," is a simple method that stops a trial if its\nperformance falls below a certain percentile of other trials at the same step (e.g.,\nwhen ",(0,i.jsx)(t.code,{children:"percentile_threshold"})," is 50, at a given point in time, if a trial ranks in the\nbottom 50% of trials, it is stopped)."]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["We make use of ",(0,i.jsx)(t.code,{children:"normalize_progressions"})," which normalizes the progression column (e.g.\ntimestamp, epochs, training data used) to be in [0, 1]. This is useful because one\ndoesn't need to know the maximum progression values of the curve (which might be,\ne.g., the total number of data points in the training dataset)."]}),"\n",(0,i.jsxs)(t.li,{children:["The ",(0,i.jsx)(t.code,{children:"min_progression"})," parameter specifies that trials should only be considered for\nstopping if the latest progression value is greater than this threshold."]}),"\n",(0,i.jsxs)(t.li,{children:["The ",(0,i.jsx)(t.code,{children:"min_curves"})," parameter specifies the minimum number of completed curves (i.e.,\nfully completed training jobs) before early stopping will be considered. This should\nbe larger than zero if ",(0,i.jsx)(t.code,{children:"normalize_progression"})," is used. In general, we want a few\ncompleted curves to have a baseline for comparison."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Note that ",(0,i.jsx)(t.code,{children:"PercentileEarlyStoppingStrategy"})," does not make use of learning curve modeling\nor prediction. More sophisticated model-based methods will be available in future\nversions of Ax."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"percentile_early_stopping_strategy = PercentileEarlyStoppingStrategy(\n    # stop if in bottom 70% of runs at the same progression\n    percentile_threshold=70,\n    # the trial must have passed `min_progression` steps before early stopping is initiated\n    # note that we are using `normalize_progressions`, so this is on a scale of [0, 1]\n    min_progression=0.3,\n    # there must be `min_curves` completed trials and `min_curves` trials reporting data in\n    # order for early stopping to be applicable\n    min_curves=5,\n    # specify, e.g., [0, 1] if the first two trials should never be stopped\n    trial_indices_to_ignore=None,\n    # check for new data every 10 seconds\n    seconds_between_polls=10,\n    normalize_progressions=True,\n)\n"})}),"\n",(0,i.jsx)(t.h2,{id:"creating-the-ax-experiment",children:"Creating the Ax Experiment"}),"\n",(0,i.jsx)(t.p,{children:"In Ax, the Experiment object is the object that stores all the information about the\nproblem setup."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'experiment = Experiment(\n    name="torchx_mnist",\n    search_space=search_space,\n    optimization_config=opt_config,\n    runner=ax_runner,\n)\n'})}),"\n",(0,i.jsx)(t.h2,{id:"choosing-the-generationstrategy",children:"Choosing the GenerationStrategy"}),"\n",(0,i.jsxs)(t.p,{children:["A\n",(0,i.jsx)(t.a,{href:"https://ax.dev/api/modelbridge.html#ax.modelbridge.generation_strategy.GenerationStrategy",children:"GenerationStrategy"}),"\nis the abstract representation of how we would like to perform the optimization. While\nthis can be customized (if you\u2019d like to do so, see\n",(0,i.jsx)(t.a,{href:"https://ax.dev/tutorials/generation_strategy.html",children:"this tutorial"}),"), in most cases Ax\ncan automatically determine an appropriate strategy based on the search space,\noptimization config, and the total number of trials we want to run."]}),"\n",(0,i.jsx)(t.p,{children:"Typically, Ax chooses to evaluate a number of random configurations before starting a\nmodel-based Bayesian Optimization strategy."}),"\n",(0,i.jsx)(t.p,{children:'We remark that in Ax, generation strategies and early stopping strategies are separate,\na design decision motivated by ease-of-use. However, we should acknowledge that jointly\nconsidering generation and stopping using a single strategy would likely be the "proper"\nformulation.'}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"if SMOKE_TEST:\n    total_trials = 6\nelse:\n    total_trials = 15  # total evaluation budget\n\ngs = choose_generation_strategy(\n    search_space=experiment.search_space,\n    optimization_config=experiment.optimization_config,\n    num_trials=total_trials,\n)\n"})}),"\n",(0,i.jsx)(t.h2,{id:"configuring-the-scheduler",children:"Configuring the Scheduler"}),"\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.code,{children:"Scheduler"})," acts as the loop control for the optimization. It communicates with the\nbackend to launch trials, check their status, retrieve (partial) results, and\nimportantly for this tutorial, calls the early stopping strategy. If the early stopping\nstrategy suggests a trial to be the stopped, the ",(0,i.jsx)(t.code,{children:"Scheduler"})," communicates with the\nbackend to terminate the trial."]}),"\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.code,{children:"Scheduler"})," requires the ",(0,i.jsx)(t.code,{children:"Experiment"})," and the ",(0,i.jsx)(t.code,{children:"GenerationStrategy"}),". A set of options\ncan be passed in via ",(0,i.jsx)(t.code,{children:"SchedulerOptions"}),". Here, we configure the number of total\nevaluations as well as ",(0,i.jsx)(t.code,{children:"max_pending_trials"}),", the maximum number of trials that should\nrun concurrently. In our local setting, this is the number of training jobs running as\nindividual processes, while in a remote execution setting, this would be the number of\nmachines you want to use in parallel."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"scheduler = Scheduler(\n    experiment=experiment,\n    generation_strategy=gs,\n    options=SchedulerOptions(\n        total_trials=total_trials,\n        max_pending_trials=5,\n        early_stopping_strategy=percentile_early_stopping_strategy,\n    ),\n)\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"%%time\nscheduler.run_all_trials()\n"})}),"\n",(0,i.jsx)(t.h2,{id:"results",children:"Results"}),"\n",(0,i.jsx)(t.p,{children:'First, we examine the data stored on the experiment. This shows that each trial is\nassociated with an entire learning curve, represented by the column "steps".'}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"experiment.lookup_data().map_df.head(n=10)\n"})}),"\n",(0,i.jsx)(t.p,{children:"Below is a summary of the experiment, showing that a portion of trials have been early\nstopped."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"exp_to_df(experiment)\n"})}),"\n",(0,i.jsx)(t.p,{children:"We can give a very rough estimate of the amount of computational savings due to early\nstopping, by looking at the total number of steps used when early stopping is used\nversus the number of steps used if we ran all trials to completion. Note to do a true\ncomparison, one should run full HPO loops with and without early stopping (as early\nstopping will influence the model and future points selected by the generation\nstrategy)."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'map_df = experiment.lookup_data().map_df\ntrial_to_max_steps = map_df.groupby("trial_index")["step"].max()\ncompleted_trial_steps = trial_to_max_steps.iloc[0]\nsavings = 1.0 - trial_to_max_steps.sum() / (\n    completed_trial_steps * len(trial_to_max_steps)\n)\n# TODO format nicer\nprint(f"A rough estimate of the computational savings is {100 * savings}%.")\n'})}),"\n",(0,i.jsx)(t.h2,{id:"visualizations",children:"Visualizations"}),"\n",(0,i.jsx)(t.p,{children:"Finally, we show a visualization of learning curves versus actual elapsed wall time.\nThis helps to illustrate that stopped trials make room for additional trials to be run."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'# helper function for getting trial start times\ndef time_started(row):\n    trial_index = row["trial_index"]\n    return experiment.trials[trial_index].time_run_started\n\n\n# helper function for getting trial completion times\ndef time_completed(row):\n    trial_index = row["trial_index"]\n    return experiment.trials[trial_index].time_completed\n\n\n# helper function for getting relevant data from experiment\n# with early stopping into useful dfs\ndef early_stopping_exp_to_df(experiment):\n    trials_df = exp_to_df(experiment)\n    curve_df = experiment.lookup_data().map_df\n    training_row_df = (\n        curve_df.groupby("trial_index").max().reset_index()[["trial_index", "steps"]]\n    )\n    trials_df = trials_df.merge(training_row_df, on="trial_index")\n    trials_df["time_started"] = trials_df.apply(func=time_started, axis=1)\n    trials_df["time_completed"] = trials_df.apply(func=time_completed, axis=1)\n    start_time = trials_df["time_started"].min()\n    trials_df["time_started_rel"] = (\n        trials_df["time_started"] - start_time\n    ).dt.total_seconds()\n    trials_df["time_completed_rel"] = (\n        trials_df["time_completed"] - start_time\n    ).dt.total_seconds()\n    return trials_df, curve_df\n\n\ndef plot_curves_by_wall_time(trials_df, curve_df):\n    trials = set(curve_df["trial_index"])\n    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n    ax.set(xlabel="seconds since start", ylabel="validation accuracy")\n    for trial_index in trials:\n        this_trial_df = curve_df[curve_df["trial_index"] == trial_index]\n        start_time_rel = trials_df["time_started_rel"].iloc[trial_index]\n        completed_time_rel = trials_df["time_completed_rel"].iloc[trial_index]\n        total_steps = trials_df.loc[trial_index, "steps"]\n        smoothed_curve = this_trial_df["mean"].rolling(window=3).mean()\n        x = (\n            start_time_rel\n            + (completed_time_rel - start_time_rel)\n            / total_steps\n            * this_trial_df["steps"]\n        )\n        ax.plot(\n            x,\n            smoothed_curve,\n            label=f"trial #{trial_index}" if trial_index % 2 == 1 else None,\n        )\n    ax.legend()\n'})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'# wrap in try/except in case of flaky I/O issues\ntry:\n    trials_df, curve_df = early_stopping_exp_to_df(experiment)\n    plot_curves_by_wall_time(trials_df, curve_df)\nexcept Exception as e:\n    print(f"Encountered exception while plotting results: {e}")\n'})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python"})})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},1023:(e,t,n)=>{n.d(t,{A:()=>u});n(6540);var i,r=new Uint8Array(16);function a(){if(!i&&!(i="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return i(r)}const o=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;const s=function(e){return"string"==typeof e&&o.test(e)};for(var l=[],p=0;p<256;++p)l.push((p+256).toString(16).substr(1));const c=function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,n=(l[e[t+0]]+l[e[t+1]]+l[e[t+2]]+l[e[t+3]]+"-"+l[e[t+4]]+l[e[t+5]]+"-"+l[e[t+6]]+l[e[t+7]]+"-"+l[e[t+8]]+l[e[t+9]]+"-"+l[e[t+10]]+l[e[t+11]]+l[e[t+12]]+l[e[t+13]]+l[e[t+14]]+l[e[t+15]]).toLowerCase();if(!s(n))throw TypeError("Stringified UUID is invalid");return n};const d=function(e,t,n){var i=(e=e||{}).random||(e.rng||a)();if(i[6]=15&i[6]|64,i[8]=63&i[8]|128,t){n=n||0;for(var r=0;r<16;++r)t[n+r]=i[r];return t}return c(i)};var h=n(4848);const u=function(e){return(0,h.jsxs)("div",{style:{backgroundColor:"lightgray",marginBottom:"var(--ifm-leading)",borderRadius:"var(--ifm-global-radius)",boxShadow:"var(--ifm-global-shadow-lw)",overflow:"hidden",padding:"10px",font:"var(--ifm-code-font-size) / var(--ifm-pre-line-height) var(--ifm-font-family-monospace)"},children:[(0,h.jsx)("span",{style:{color:"red"},children:"Out: "}),(0,h.jsx)("pre",{style:{margin:"0px",backgroundColor:"inherit"},children:e.children.split("\n").map((function(e){return(0,h.jsx)("p",{style:{marginBottom:"0px"},children:e},d())}))})]})}},8987:(e,t,n)=>{n.d(t,{A:()=>a});n(6540);var i=n(8774),r=n(4848);const a=function(e){var t=e.githubUrl,n=e.colabUrl;return(0,r.jsxs)("div",{className:"link-buttons",children:[(0,r.jsx)(i.A,{to:t,children:"Open in GitHub"}),(0,r.jsx)("div",{}),(0,r.jsx)(i.A,{to:n,children:"Run in Google Colab"})]})}},290:(e,t,n)=>{n(6540);var i=n(3259),r=n.n(i),a=(n(2303),n(4848));r()({loader:function(){return n.e(236).then(n.bind(n,1236))},loading:function(e){return e.timedOut?(0,a.jsx)("blockquote",{children:"Error: Loading Plotly timed out."}):(0,a.jsx)("div",{children:"loading..."})},timeout:1e4})},8453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>s});var i=n(6540);const r={},a=i.createContext(r);function o(e){const t=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(a.Provider,{value:t},e.children)}}}]);