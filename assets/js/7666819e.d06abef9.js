"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[879],{5599:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>d});var i=a(4848),t=a(8453),s=a(8987);a(1023),a(290);const r={title:"High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces (SAASBO)",sidebar_label:"High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces (SAASBO)"},o="High-Dimensional Bayesian Optimization with SAASBO",l={id:"tutorials/saasbo/index",title:"High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces (SAASBO)",description:"<LinkButtons",source:"@site/../docs/tutorials/saasbo/index.mdx",sourceDirName:"tutorials/saasbo",slug:"/tutorials/saasbo/",permalink:"/Ax/docs/tutorials/saasbo/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces (SAASBO)",sidebar_label:"High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces (SAASBO)"},sidebar:"tutorials",previous:{title:"Multi-Objective Optimization",permalink:"/Ax/docs/tutorials/multiobjective_optimization/"},next:{title:"Fully Bayesian, High-Dimensional, Multi-Objective Optimization",permalink:"/Ax/docs/tutorials/saasbo_nehvi/"}},c={},d=[{value:"Setup search space and metric",id:"setup-search-space-and-metric",level:2},{value:"Run benchmark",id:"run-benchmark",level:2},{value:"Plot results",id:"plot-results",level:2},{value:"SAAS model fit",id:"saas-model-fit",level:2},{value:"Cross-validation plot",id:"cross-validation-plot",level:3},{value:"Lengthscales",id:"lengthscales",level:3}];function m(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.A,{githubUrl:"",colabUrl:""}),"\n",(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"high-dimensional-bayesian-optimization-with-saasbo",children:"High-Dimensional Bayesian Optimization with SAASBO"})}),"\n",(0,i.jsx)(n.p,{children:"This tutorial shows how to use the Sparse Axis-Aligned Subspace Bayesian Optimization\n(SAASBO) method for high-dimensional Bayesian optimization [1]. SAASBO places strong\npriors on the inverse lengthscales to avoid overfitting in high-dimensional spaces.\nSpecifically, SAASBO uses a hierarchical sparsity prior consisting of a global shrinkage\nparameter $\\tau \\sim \\mathcal{HC}(\\beta)$ and inverse lengthscales\n$\\rho_d \\sim \\mathcal{HC}(\\tau)$ for $d=1, ..., D$, where $\\mathcal{HC}$ is the\nhalf-Cauchy distribution. While half-Cauchy priors favor values near zero they also have\nheavy tails, which allows the inverse lengthscales of the most important parameters to\nescape zero. To do inference in the SAAS model we use Hamiltonian Monte Carlo (HMC) as\nwe found that to outperform MAP inference."}),"\n",(0,i.jsx)(n.p,{children:"We find that SAASBO performs well on problems with hundreds of dimensions. As we rely on\nHMC and in particular the No-U-Turn-Sampler (NUTS) for inference, the overhead of SAASBO\nscales cubically with the number of datapoints. Depending on the problem, using more\nthan $100$ evaluations may not be feasible as SAASBO is designed for problems with a\nlimited evaluation budget."}),"\n",(0,i.jsx)(n.p,{children:"[1] D. Eriksson, M. Jankowiak. High-Dimensional Bayesian Optimization with Sparse\nAxis-Aligned Subspaces. Proceedings of the Thirty-Seventh Conference on Uncertainty in\nArtificial Intelligence, 2021."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import os\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nfrom ax import Data, Experiment, ParameterType, RangeParameter, SearchSpace\nfrom ax.core.metric import Metric\nfrom ax.core.objective import Objective\nfrom ax.core.optimization_config import OptimizationConfig\nfrom ax.metrics.branin import BraninMetric\nfrom ax.modelbridge.cross_validation import cross_validate\nfrom ax.modelbridge.registry import Models\nfrom ax.models.torch.botorch_modular.surrogate import Surrogate\nfrom ax.runners.synthetic import SyntheticRunner\nfrom botorch.models.fully_bayesian import SaasFullyBayesianSingleTaskGP\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'SMOKE_TEST = os.environ.get("SMOKE_TEST")\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'torch.manual_seed(12345)  # To always get the same Sobol points\ntkwargs = {\n    "dtype": torch.double,\n    "device": torch.device("cuda" if torch.cuda.is_available() else "cpu"),\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"setup-search-space-and-metric",children:"Setup search space and metric"}),"\n",(0,i.jsx)(n.p,{children:"In this simple experiment we use the Branin function embedded in a 30-dimensional space.\nAdditional resources:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["To set up a custom metric for your problem, refer to the dedicated section of the\nDeveloper API tutorial:\n",(0,i.jsx)(n.a,{href:"https://ax.dev/tutorials/gpei_hartmann_developer.html#8.-Defining-custom-metrics",children:"https://ax.dev/tutorials/gpei_hartmann_developer.html#8.-Defining-custom-metrics"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["To avoid needing to setup up custom metrics by Ax Service API:\n",(0,i.jsx)(n.a,{href:"https://ax.dev/tutorials/gpei_hartmann_service.html",children:"https://ax.dev/tutorials/gpei_hartmann_service.html"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'search_space = SearchSpace(\n    parameters=[\n        RangeParameter(\n            name=f"x{i}", parameter_type=ParameterType.FLOAT, lower=-5.0, upper=10.0\n        )\n        for i in range(25)\n    ]\n    + [\n        RangeParameter(\n            name=f"x{i + 25}",\n            parameter_type=ParameterType.FLOAT,\n            lower=0.0,\n            upper=15.0,\n        )\n        for i in range(25)\n    ]\n)\n\noptimization_config = OptimizationConfig(\n    objective=Objective(\n        metric=BraninMetric(\n            name="objective",\n            param_names=["x19", "x34"],\n             # Set noise_sd=None if you want to learn the noise, set to 0.0 for no noise\n            noise_sd=1e-4, \n        ),\n        minimize=True,\n    )\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"run-benchmark",children:"Run benchmark"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'N_INIT = 10\nBATCH_SIZE = 3\nN_BATCHES = 1 if SMOKE_TEST else 10\n\nprint(f"Doing {N_INIT + N_BATCHES * BATCH_SIZE} evaluations")\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Experiment\nexperiment = Experiment(\n    name="saasbo_experiment",\n    search_space=search_space,\n    optimization_config=optimization_config,\n    runner=SyntheticRunner(),\n)\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Initial Sobol points\nsobol = Models.SOBOL(search_space=experiment.search_space)\nfor _ in range(N_INIT):\n    experiment.new_trial(sobol.gen(1)).run()\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'%%time\n# Run SAASBO\ndata = experiment.fetch_data()\nfor i in range(N_BATCHES):\n    model = Models.SAASBO(experiment=experiment, data=data)\n    generator_run = model.gen(BATCH_SIZE)\n    trial = experiment.new_batch_trial(generator_run=generator_run)\n    trial.run()\n    data = Data.from_multiple_data([data, trial.fetch_data()])\n\n    new_value = trial.fetch_data().df["mean"].min()\n    print(\n        f"Iteration: {i}, Best in iteration {new_value:.3f}, Best so far: {data.df[\'mean\'].min():.3f}"\n    )\n'})}),"\n",(0,i.jsx)(n.h2,{id:"plot-results",children:"Plot results"}),"\n",(0,i.jsx)(n.p,{children:"SAASBO is able to find a solution close to the global optimal value of 0.398"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'%matplotlib inline\nmatplotlib.rcParams.update({"font.size": 16})\n\n\nfig, ax = plt.subplots(figsize=(8, 6))\nres_saasbo = data.df["mean"]\nax.plot(np.minimum.accumulate(res_saasbo), color="b", label="SAASBO")\nax.plot([0, len(res_saasbo)], [0.398, 0.398], "--", c="g", lw=3, label="Optimal value")\nax.grid(True)\nax.set_title("Branin, D=50", fontsize=20)\nax.set_xlabel("Number of evaluations", fontsize=20)\nax.set_xlim([0, len(res_saasbo)])\nax.set_ylabel("Best value found", fontsize=20)\nax.set_ylim([0, 8])\nax.legend(fontsize=18)\nplt.show()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"saas-model-fit",children:"SAAS model fit"}),"\n",(0,i.jsxs)(n.p,{children:["We can also instantiate a SAAS model via ",(0,i.jsx)(n.code,{children:"Models.BOTORCH_MODULAR"})," by specifying a\n",(0,i.jsx)(n.code,{children:"SaasFullyBayesianSingleTaskGP"})," as the ",(0,i.jsx)(n.code,{children:"botorch_model_class"}),". This also gives us the\noption to change several Pyro-specific parameters such as ",(0,i.jsx)(n.code,{children:"num_samples"})," and\n",(0,i.jsx)(n.code,{children:"warmup_steps"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'model = Models.BOTORCH_MODULAR(\n    experiment=experiment,\n    data=data,\n    surrogate=Surrogate(\n        botorch_model_class=SaasFullyBayesianSingleTaskGP,\n        mll_options={\n            "num_samples": 256,  # Increasing this may result in better model fits\n            "warmup_steps": 512,  # Increasing this may result in better model fits\n        },\n    )\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"cross-validation-plot",children:"Cross-validation plot"}),"\n",(0,i.jsx)(n.p,{children:"We have tools for cross-validation in Ax, but plotly doesn't render on Github so we make\na simple plot using Matplotlib here. To use the built-in cross-validation functionality,\nyou can do something like this:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"from ax.modelbridge.cross_validation import cross_validate, compute_diagnostics\nfrom ax.plot.diagnostic import interact_cross_validation\nfrom ax.utils.notebook.plotting import render, init_notebook_plotting\n\n\ncv = cross_validate(model)\ndiagnostics = compute_diagnostics(cv)\ninit_notebook_plotting()\nplotconfig = interact_cross_validation(cv)\nrender(plotconfig)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Cross-validate model\ncv = cross_validate(model)\ny_true = np.stack([cv_.observed.data.means for cv_ in cv]).ravel()\ny_saas_mean = np.stack([cv_.predicted.means for cv_ in cv]).ravel()\ny_saas_std = np.stack(\n    [np.sqrt(np.diag(cv_.predicted.covariance)) for cv_ in cv]\n).ravel()\n\n# Cross-validation plot\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\nmin_val, max_val = -5, 120\nax.plot([min_val, max_val], [min_val, max_val], "b--", lw=2)\nmarkers, caps, bars = ax.errorbar(\n    y_true,\n    y_saas_mean,\n    yerr=1.96 * y_saas_std,\n    fmt=".",\n    capsize=4,\n    elinewidth=2.0,\n    ms=14,\n    c="k",\n    ecolor="gray",\n)\n[bar.set_alpha(0.8) for bar in bars]\n[cap.set_alpha(0.8) for cap in caps]\nax.set_xlim([min_val, max_val])\nax.set_ylim([min_val, max_val])\nax.set_xlabel("True value", fontsize=20)\nax.set_ylabel("Predicted value", fontsize=20)\nax.grid(True)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"lengthscales",children:"Lengthscales"}),"\n",(0,i.jsx)(n.p,{children:"As SAASBO places strong priors on the inverse lengthscales, we only expect parameters 19\nand 44 to be identified as important by the model since the other parameters have no\neffect. We can confirm that this is the case below as the lengthscales of parameters 19\nand 44 are close to 1 with all other lengthscales being larger than 1000."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'median_lengthscales = (\n    model.model.surrogate.model\n    .covar_module.base_kernel.lengthscale.squeeze()\n    .median(axis=0)\n    .values\n)\nfor i in median_lengthscales.argsort()[:10]:\n    print(f"Parameter {i:2}) Median lengthscale = {median_lengthscales[i]:.2e}")\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python"})})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}},1023:(e,n,a)=>{a.d(n,{A:()=>h});a(6540);var i,t=new Uint8Array(16);function s(){if(!i&&!(i="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return i(t)}const r=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;const o=function(e){return"string"==typeof e&&r.test(e)};for(var l=[],c=0;c<256;++c)l.push((c+256).toString(16).substr(1));const d=function(e){var n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,a=(l[e[n+0]]+l[e[n+1]]+l[e[n+2]]+l[e[n+3]]+"-"+l[e[n+4]]+l[e[n+5]]+"-"+l[e[n+6]]+l[e[n+7]]+"-"+l[e[n+8]]+l[e[n+9]]+"-"+l[e[n+10]]+l[e[n+11]]+l[e[n+12]]+l[e[n+13]]+l[e[n+14]]+l[e[n+15]]).toLowerCase();if(!o(a))throw TypeError("Stringified UUID is invalid");return a};const m=function(e,n,a){var i=(e=e||{}).random||(e.rng||s)();if(i[6]=15&i[6]|64,i[8]=63&i[8]|128,n){a=a||0;for(var t=0;t<16;++t)n[a+t]=i[t];return n}return d(i)};var p=a(4848);const h=function(e){return(0,p.jsxs)("div",{style:{backgroundColor:"lightgray",marginBottom:"var(--ifm-leading)",borderRadius:"var(--ifm-global-radius)",boxShadow:"var(--ifm-global-shadow-lw)",overflow:"hidden",padding:"10px",font:"var(--ifm-code-font-size) / var(--ifm-pre-line-height) var(--ifm-font-family-monospace)"},children:[(0,p.jsx)("span",{style:{color:"red"},children:"Out: "}),(0,p.jsx)("pre",{style:{margin:"0px",backgroundColor:"inherit"},children:e.children.split("\n").map((function(e){return(0,p.jsx)("p",{style:{marginBottom:"0px"},children:e},m())}))})]})}},8987:(e,n,a)=>{a.d(n,{A:()=>s});a(6540);var i=a(8774),t=a(4848);const s=function(e){var n=e.githubUrl,a=e.colabUrl;return(0,t.jsxs)("div",{className:"link-buttons",children:[(0,t.jsx)(i.A,{to:n,children:"Open in GitHub"}),(0,t.jsx)("div",{}),(0,t.jsx)(i.A,{to:a,children:"Run in Google Colab"})]})}},290:(e,n,a)=>{a(6540);var i=a(3259),t=a.n(i),s=(a(2303),a(4848));t()({loader:function(){return a.e(236).then(a.bind(a,1236))},loading:function(e){return e.timedOut?(0,s.jsx)("blockquote",{children:"Error: Loading Plotly timed out."}):(0,s.jsx)("div",{children:"loading..."})},timeout:1e4})},8453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>o});var i=a(6540);const t={},s=i.createContext(t);function r(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);