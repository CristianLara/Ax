"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[396],{950:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>l,toc:()=>p});var i=n(4848),o=n(8453),r=n(8987);n(1023),n(290);const a={title:"Multi-Objective Optimization",sidebar_label:"Multi-Objective Optimization"},s="Multi-Objective Optimization Ax API",l={id:"tutorials/multiobjective_optimization/index",title:"Multi-Objective Optimization",description:"<LinkButtons",source:"@site/../docs/tutorials/multiobjective_optimization/index.mdx",sourceDirName:"tutorials/multiobjective_optimization",slug:"/tutorials/multiobjective_optimization/",permalink:"/Ax/docs/tutorials/multiobjective_optimization/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"Multi-Objective Optimization",sidebar_label:"Multi-Objective Optimization"},sidebar:"tutorials",previous:{title:"Multi-Task Modeling",permalink:"/Ax/docs/tutorials/multi_task/"},next:{title:"High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces (SAASBO)",permalink:"/Ax/docs/tutorials/saasbo/"}},c={},p=[{value:"Using the Service API",id:"using-the-service-api",level:3},{value:"Create an Evaluation Function",id:"create-an-evaluation-function",level:3},{value:"Run Optimization",id:"run-optimization",level:3},{value:"Plot Pareto Frontier",id:"plot-pareto-frontier",level:3},{value:"Problem Statement",id:"problem-statement",level:3},{value:"Pareto Optimality",id:"pareto-optimality",level:3},{value:"Evaluating the Quality of a Pareto Front (Hypervolume)",id:"evaluating-the-quality-of-a-pareto-front-hypervolume",level:3},{value:"Set Objective Thresholds to focus candidate generation in a region of interest",id:"set-objective-thresholds-to-focus-candidate-generation-in-a-region-of-interest",level:3},{value:"Further Information",id:"further-information",level:3},{value:"Setup",id:"setup",level:2},{value:"Define experiment configurations",id:"define-experiment-configurations",level:2},{value:"Search Space",id:"search-space",level:3},{value:"MultiObjectiveOptimizationConfig",id:"multiobjectiveoptimizationconfig",level:3},{value:"Define experiment creation utilities",id:"define-experiment-creation-utilities",level:2},{value:"qNEHVI",id:"qnehvi",level:2},{value:"Plot qNEHVI Pareto Frontier based on model posterior",id:"plot-qnehvi-pareto-frontier-based-on-model-posterior",level:2},{value:"qNParEGO",id:"qnparego",level:2},{value:"Plot qNParEGO Pareto Frontier based on model posterior",id:"plot-qnparego-pareto-frontier-based-on-model-posterior",level:2},{value:"Plot empirical data",id:"plot-empirical-data",level:2},{value:"Plot observed hypervolume, with color representing the iteration that a point was generated on.",id:"plot-observed-hypervolume-with-color-representing-the-iteration-that-a-point-was-generated-on",level:4},{value:"Plot the results",id:"plot-the-results",level:4}];function h(e){const t={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.A,{githubUrl:"",colabUrl:""}),"\n",(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"multi-objective-optimization-ax-api",children:"Multi-Objective Optimization Ax API"})}),"\n",(0,i.jsx)(t.h3,{id:"using-the-service-api",children:"Using the Service API"}),"\n",(0,i.jsxs)(t.p,{children:["For Multi-objective optimization (MOO) in the ",(0,i.jsx)(t.code,{children:"AxClient"}),", objectives are specified\nthrough the ",(0,i.jsx)(t.code,{children:"ObjectiveProperties"})," dataclass. An ",(0,i.jsx)(t.code,{children:"ObjectiveProperties"})," requires a boolean\n",(0,i.jsx)(t.code,{children:"minimize"}),", and also accepts an optional floating point ",(0,i.jsx)(t.code,{children:"threshold"}),". If a ",(0,i.jsx)(t.code,{children:"threshold"})," is\nnot specified, Ax will infer it through the use of heuristics. If the user knows the\nregion of interest (because they have specs or prior knowledge), then specifying the\nthresholds is preferable to inferring it. But if the user would need to guess, inferring\nis preferable."]}),"\n",(0,i.jsxs)(t.p,{children:["To learn more about how to choose a threshold, see\n",(0,i.jsx)(t.a,{href:"#Set-Objective-Thresholds-to-focus-candidate-generation-in-a-region-of-interest",children:"Set Objective Thresholds to focus candidate generation in a region of interest"}),".\nSee the ",(0,i.jsx)(t.a,{href:"/tutorials/gpei_hartmann_service.html",children:"Service API Tutorial"})," for more\ninfomation on running experiments with the Service API."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"import torch\nfrom ax.plot.pareto_frontier import plot_pareto_frontier\nfrom ax.plot.pareto_utils import compute_posterior_pareto_frontier\nfrom ax.service.ax_client import AxClient\nfrom ax.service.utils.instantiation import ObjectiveProperties\n\n# Plotting imports and initialization\nfrom ax.utils.notebook.plotting import init_notebook_plotting, render\nfrom botorch.test_functions.multi_objective import BraninCurrin\n\ninit_notebook_plotting()\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'# Load our sample 2-objective problem\nbranin_currin = BraninCurrin(negate=True).to(\n    dtype=torch.double,\n    device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),\n)\n'})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'ax_client = AxClient()\nax_client.create_experiment(\n    name="moo_experiment",\n    parameters=[\n        {\n            "name": f"x{i+1}",\n            "type": "range",\n            "bounds": [0.0, 1.0],\n        }\n        for i in range(2)\n    ],\n    objectives={\n        # `threshold` arguments are optional\n        "a": ObjectiveProperties(minimize=False, threshold=branin_currin.ref_point[0]),\n        "b": ObjectiveProperties(minimize=False, threshold=branin_currin.ref_point[1]),\n    },\n    overwrite_existing_experiment=True,\n    is_test=True,\n)\n'})}),"\n",(0,i.jsx)(t.h3,{id:"create-an-evaluation-function",children:"Create an Evaluation Function"}),"\n",(0,i.jsxs)(t.p,{children:["In the case of MOO experiments, evaluation functions can be any arbitrary function that\ntakes in a ",(0,i.jsx)(t.code,{children:"dict"})," of parameter names mapped to values and returns a ",(0,i.jsx)(t.code,{children:"dict"})," of objective\nnames mapped to a ",(0,i.jsx)(t.code,{children:"tuple"})," of mean and SEM values."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'def evaluate(parameters):\n    evaluation = branin_currin(\n        torch.tensor([parameters.get("x1"), parameters.get("x2")])\n    )\n    # In our case, standard error is 0, since we are computing a synthetic function.\n    # Set standard error to None if the noise level is unknown.\n    return {"a": (evaluation[0].item(), 0.0), "b": (evaluation[1].item(), 0.0)}\n'})}),"\n",(0,i.jsx)(t.h3,{id:"run-optimization",children:"Run Optimization"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"for i in range(25):\n    parameters, trial_index = ax_client.get_next_trial()\n    # Local evaluation here can be replaced with deployment to external system.\n    ax_client.complete_trial(trial_index=trial_index, raw_data=evaluate(parameters))\n"})}),"\n",(0,i.jsx)(t.h3,{id:"plot-pareto-frontier",children:"Plot Pareto Frontier"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'objectives = ax_client.experiment.optimization_config.objective.objectives\nfrontier = compute_posterior_pareto_frontier(\n    experiment=ax_client.experiment,\n    data=ax_client.experiment.fetch_data(),\n    primary_objective=objectives[1].metric,\n    secondary_objective=objectives[0].metric,\n    absolute_metrics=["a", "b"],\n    num_points=20,\n)\nrender(plot_pareto_frontier(frontier, CI_level=0.90))\n'})}),"\n",(0,i.jsx)(t.h1,{id:"deep-dive",children:"Deep Dive"}),"\n",(0,i.jsx)(t.p,{children:"In the rest of this tutorial, we will show two algorithms available in Ax for\nmulti-objective optimization and visualize how they compare to eachother and to\nquasirandom search."}),"\n",(0,i.jsxs)(t.p,{children:["MOO covers the case where we care about multiple outcomes in our experiment but we do\nnot know before hand a specific weighting of those objectives (covered by\n",(0,i.jsx)(t.code,{children:"ScalarizedObjective"}),") or a specific constraint on one objective (covered by\n",(0,i.jsx)(t.code,{children:"OutcomeConstraint"}),"s) that will produce the best result."]}),"\n",(0,i.jsx)(t.p,{children:"The solution in this case is to find a whole Pareto frontier, a surface in outcome-space\ncontaining points that can't be improved on in every outcome. This shows us the\ntradeoffs between objectives that we can choose to make."}),"\n",(0,i.jsx)(t.h3,{id:"problem-statement",children:"Problem Statement"}),"\n",(0,i.jsx)(t.p,{children:"Optimize a list of M objective functions\n$ \\bigl(f^{(1)}( x),..., f^{(M)}( x) \\bigr)$ over a bounded search space\n$\\mathcal X \\subset \\mathbb R^d$."}),"\n",(0,i.jsx)(t.p,{children:"We assume $f^{(i)}$ are expensive-to-evaluate black-box functions with no known\nanalytical expression, and no observed gradients. For instance, a machine learning model\nwhere we're interested in maximizing accuracy and minimizing inference time, with\n$\\mathcal X$ the set of possible configuration spaces"}),"\n",(0,i.jsx)(t.h3,{id:"pareto-optimality",children:"Pareto Optimality"}),"\n",(0,i.jsxs)(t.p,{children:["In a multi-objective optimization problem, there typically is no single best solution.\nRather, the ",(0,i.jsx)(t.em,{children:"goal"})," is to identify the set of Pareto optimal solutions such that any\nimprovement in one objective means deteriorating another. Provided with the Pareto set,\ndecision-makers can select an objective trade-off according to their preferences. In the\nplot below, the red dots are the Pareto optimal solutions (assuming both objectives are\nto be minimized). ",(0,i.jsx)(t.img,{src:"attachment:pareto_front%20%281%29.png",alt:"pareto front"})]}),"\n",(0,i.jsx)(t.h3,{id:"evaluating-the-quality-of-a-pareto-front-hypervolume",children:"Evaluating the Quality of a Pareto Front (Hypervolume)"}),"\n",(0,i.jsxs)(t.p,{children:["Given a reference point $ r \\in \\mathbb R^M$, which we represent as a list of M\n",(0,i.jsx)(t.code,{children:"ObjectiveThreshold"}),"s, one for each coordinate, the hypervolume (HV) of a Pareto set\n$\\mathcal P = { f(x_i)}_{i=1}^{|\\mathcal P|}$ is the volume of the space dominated\n(superior in every one of our M objectives) by $\\mathcal P$ and bounded from above by a\npoint $ r$. The reference point should be set to be slightly worse (10% is reasonable)\nthan the worst value of each objective that a decision maker would tolerate. In the\nfigure below, the grey area is the hypervolume in this 2-objective problem.\n",(0,i.jsx)(t.img,{src:"attachment:hv_figure%20%281%29.png",alt:"hv_figure"})]}),"\n",(0,i.jsx)(t.h3,{id:"set-objective-thresholds-to-focus-candidate-generation-in-a-region-of-interest",children:"Set Objective Thresholds to focus candidate generation in a region of interest"}),"\n",(0,i.jsx)(t.p,{children:"The below plots show three different sets of points generated by the qNEHVI [1]\nalgorithm with different objective thresholds (aka reference points). Note that here we\nuse absolute thresholds, but thresholds can also be relative to a status_quo arm."}),"\n",(0,i.jsxs)(t.p,{children:["The first plot shows the points without the ",(0,i.jsx)(t.code,{children:"ObjectiveThreshold"}),"s visible (they're set\nfar below the origin of the graph)."]}),"\n",(0,i.jsx)(t.p,{children:"The second shows the points generated with (-18, -6) as thresholds. The regions\nviolating the thresholds are greyed out. Only the white region in the upper right\nexceeds both threshold, points in this region dominate the intersection of these\nthresholds (this intersection is the reference point). Only points in this region\ncontribute to the hypervolume objective. A few exploration points are not in the valid\nregion, but almost all the rest of the points are."}),"\n",(0,i.jsxs)(t.p,{children:["The third shows points generated with a very strict pair of thresholds, (-18, -2). Only\nthe white region in the upper right exceeds both thresholds. Many points do not lie in\nthe dominating region, but there are still more focused there than in the second\nexamples.\n",(0,i.jsx)(t.img,{src:"attachment:objective_thresholds_comparison.png",alt:"objective_thresholds_comparison.png"})]}),"\n",(0,i.jsx)(t.h3,{id:"further-information",children:"Further Information"}),"\n",(0,i.jsx)(t.p,{children:"A deeper explanation of our the qNEHVI [1] and qNParEGO [2] algorithms this notebook\nexplores can be found at"}),"\n",(0,i.jsxs)(t.p,{children:["[1]\n",(0,i.jsx)(t.a,{href:"https://arxiv.org/abs/2105.08195",children:"S. Daulton, M. Balandat, and E. Bakshy. Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement. Advances in Neural Information Processing Systems 34, 2021."})]}),"\n",(0,i.jsxs)(t.p,{children:["[2]\n",(0,i.jsx)(t.a,{href:"https://arxiv.org/abs/2006.05078",children:"S. Daulton, M. Balandat, and E. Bakshy. Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization. Advances in Neural Information Processing Systems 33, 2020."})]}),"\n",(0,i.jsxs)(t.p,{children:["In addition, the underlying BoTorch implementation has a researcher-oriented tutorial at\n",(0,i.jsx)(t.a,{href:"https://botorch.org/tutorials/multi_objective_bo",children:"https://botorch.org/tutorials/multi_objective_bo"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"setup",children:"Setup"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"import numpy as np\nimport pandas as pd\nfrom ax.core.data import Data\nfrom ax.core.experiment import Experiment\nfrom ax.core.metric import Metric\nfrom ax.core.objective import MultiObjective, Objective\nfrom ax.core.optimization_config import (\n    MultiObjectiveOptimizationConfig,\n    ObjectiveThreshold,\n)\n\nfrom ax.core.parameter import ParameterType, RangeParameter\nfrom ax.core.search_space import SearchSpace\nfrom ax.metrics.noisy_function import NoisyFunctionMetric\n\n# Analysis utilities, including a method to evaluate hypervolumes\nfrom ax.modelbridge.modelbridge_utils import observed_hypervolume\nfrom ax.modelbridge.registry import Models\nfrom ax.runners.synthetic import SyntheticRunner\nfrom ax.service.utils.report_utils import exp_to_df\n\n# BoTorch acquisition class for ParEGO\nfrom botorch.acquisition.multi_objective.parego import qLogNParEGO\n"})}),"\n",(0,i.jsx)(t.h2,{id:"define-experiment-configurations",children:"Define experiment configurations"}),"\n",(0,i.jsx)(t.h3,{id:"search-space",children:"Search Space"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'x1 = RangeParameter(name="x1", lower=0, upper=1, parameter_type=ParameterType.FLOAT)\nx2 = RangeParameter(name="x2", lower=0, upper=1, parameter_type=ParameterType.FLOAT)\n\nsearch_space = SearchSpace(parameters=[x1, x2])\n'})}),"\n",(0,i.jsx)(t.h3,{id:"multiobjectiveoptimizationconfig",children:"MultiObjectiveOptimizationConfig"}),"\n",(0,i.jsxs)(t.p,{children:["To optimize multiple objective we must create a ",(0,i.jsx)(t.code,{children:"MultiObjective"})," containing the metrics\nwe'll optimize and ",(0,i.jsx)(t.code,{children:"MultiObjectiveOptimizationConfig"})," (which contains\n",(0,i.jsx)(t.code,{children:"ObjectiveThreshold"}),"s) instead of our more typical ",(0,i.jsx)(t.code,{children:"Objective"})," and ",(0,i.jsx)(t.code,{children:"OptimizationConfig"})]}),"\n",(0,i.jsxs)(t.p,{children:["We define ",(0,i.jsx)(t.code,{children:"NoisyFunctionMetric"}),"s to wrap our synthetic Branin-Currin problem's outputs.\nAdd noise to see how robust our different optimization algorithms are."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'class MetricA(NoisyFunctionMetric):\n    def f(self, x: np.ndarray) -> float:\n        return float(branin_currin(torch.tensor(x))[0])\n\n\nclass MetricB(NoisyFunctionMetric):\n    def f(self, x: np.ndarray) -> float:\n        return float(branin_currin(torch.tensor(x))[1])\n\n\nmetric_a = MetricA("a", ["x1", "x2"], noise_sd=0.0, lower_is_better=False)\nmetric_b = MetricB("b", ["x1", "x2"], noise_sd=0.0, lower_is_better=False)\n'})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"mo = MultiObjective(\n    objectives=[Objective(metric=metric_a), Objective(metric=metric_b)],\n)\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"objective_thresholds = [\n    ObjectiveThreshold(metric=metric, bound=val, relative=False)\n    for metric, val in zip(mo.metrics, branin_currin.ref_point)\n]\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"optimization_config = MultiObjectiveOptimizationConfig(\n    objective=mo,\n    objective_thresholds=objective_thresholds,\n)\n"})}),"\n",(0,i.jsx)(t.h2,{id:"define-experiment-creation-utilities",children:"Define experiment creation utilities"}),"\n",(0,i.jsx)(t.p,{children:"These construct our experiment, then initialize with Sobol points before we fit a\nGaussian Process model to those initial points."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"# Reasonable defaults for number of quasi-random initialization points and for subsequent model-generated trials.\nN_INIT = 6\nN_BATCH = 25\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'def build_experiment():\n    experiment = Experiment(\n        name="pareto_experiment",\n        search_space=search_space,\n        optimization_config=optimization_config,\n        runner=SyntheticRunner(),\n    )\n    return experiment\n'})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"## Initialize with Sobol samples\ndef initialize_experiment(experiment):\n    sobol = Models.SOBOL(search_space=experiment.search_space, seed=1234)\n    for _ in range(N_INIT):\n        experiment.new_trial(sobol.gen(1)).run()\n    return experiment.fetch_data()\n"})}),"\n",(0,i.jsx)(t.h1,{id:"sobol",children:"Sobol"}),"\n",(0,i.jsx)(t.p,{children:"We use quasirandom points as a fast baseline for evaluating the quality of our\nmulti-objective optimization algorithms."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"sobol_experiment = build_experiment()\nsobol_data = initialize_experiment(sobol_experiment)\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'sobol_model = Models.SOBOL(\n    experiment=sobol_experiment,\n    data=sobol_data,\n)\nsobol_hv_list = []\nfor i in range(N_BATCH):\n    generator_run = sobol_model.gen(1)\n    trial = sobol_experiment.new_trial(generator_run=generator_run)\n    trial.run()\n    exp_df = exp_to_df(sobol_experiment)\n    outcomes = np.array(exp_df[["a", "b"]], dtype=np.double)\n    # Fit a GP-based model in order to calculate hypervolume.\n    # We will not use this model to generate new points.\n    dummy_model = Models.BOTORCH_MODULAR(\n        experiment=sobol_experiment,\n        data=sobol_experiment.fetch_data(),\n    )\n    try:\n        hv = observed_hypervolume(modelbridge=dummy_model)\n    except:\n        hv = 0\n        print("Failed to compute hv")\n    sobol_hv_list.append(hv)\n    print(f"Iteration: {i}, HV: {hv}")\n\nsobol_outcomes = np.array(exp_to_df(sobol_experiment)[["a", "b"]], dtype=np.double)\n'})}),"\n",(0,i.jsx)(t.h2,{id:"qnehvi",children:"qNEHVI"}),"\n",(0,i.jsx)(t.p,{children:"Noisy Expected Hypervolume Improvement. This is our current recommended algorithm for\nmulti-objective optimization."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"ehvi_experiment = build_experiment()\nehvi_data = initialize_experiment(ehvi_experiment)\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'ehvi_hv_list = []\nehvi_model = None\nfor i in range(N_BATCH):\n    ehvi_model = Models.BOTORCH_MODULAR(\n        experiment=ehvi_experiment,\n        data=ehvi_data,\n    )\n    generator_run = ehvi_model.gen(1)\n    trial = ehvi_experiment.new_trial(generator_run=generator_run)\n    trial.run()\n    ehvi_data = Data.from_multiple_data([ehvi_data, trial.fetch_data()])\n\n    exp_df = exp_to_df(ehvi_experiment)\n    outcomes = np.array(exp_df[["a", "b"]], dtype=np.double)\n    try:\n        hv = observed_hypervolume(modelbridge=ehvi_model)\n    except:\n        hv = 0\n        print("Failed to compute hv")\n    ehvi_hv_list.append(hv)\n    print(f"Iteration: {i}, HV: {hv}")\n\nehvi_outcomes = np.array(exp_to_df(ehvi_experiment)[["a", "b"]], dtype=np.double)\n'})}),"\n",(0,i.jsx)(t.h2,{id:"plot-qnehvi-pareto-frontier-based-on-model-posterior",children:"Plot qNEHVI Pareto Frontier based on model posterior"}),"\n",(0,i.jsx)(t.p,{children:"The plotted points are samples from the fitted model's posterior, not observed samples."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'frontier = compute_posterior_pareto_frontier(\n    experiment=ehvi_experiment,\n    data=ehvi_experiment.fetch_data(),\n    primary_objective=metric_b,\n    secondary_objective=metric_a,\n    absolute_metrics=["a", "b"],\n    num_points=20,\n)\n\nrender(plot_pareto_frontier(frontier, CI_level=0.90))\n'})}),"\n",(0,i.jsx)(t.h2,{id:"qnparego",children:"qNParEGO"}),"\n",(0,i.jsxs)(t.p,{children:["This is a good alternative algorithm for multi-objective optimization when qNEHVI runs\ntoo slowly. We use ",(0,i.jsx)(t.code,{children:"qLogNParEGO"})," acquisition function with Modular BoTorch Model."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"parego_experiment = build_experiment()\nparego_data = initialize_experiment(parego_experiment)\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'parego_hv_list = []\nparego_model = None\nfor i in range(N_BATCH):\n    parego_model = Models.BOTORCH_MODULAR(\n        experiment=parego_experiment,\n        data=parego_data,\n        botorch_acqf_class=qLogNParEGO,\n    )\n    generator_run = parego_model.gen(1)\n    trial = parego_experiment.new_trial(generator_run=generator_run)\n    trial.run()\n    parego_data = Data.from_multiple_data([parego_data, trial.fetch_data()])\n\n    exp_df = exp_to_df(parego_experiment)\n    outcomes = np.array(exp_df[["a", "b"]], dtype=np.double)\n    try:\n        hv = observed_hypervolume(modelbridge=parego_model)\n    except:\n        hv = 0\n        print("Failed to compute hv")\n    parego_hv_list.append(hv)\n    print(f"Iteration: {i}, HV: {hv}")\n\nparego_outcomes = np.array(exp_to_df(parego_experiment)[["a", "b"]], dtype=np.double)\n'})}),"\n",(0,i.jsx)(t.h2,{id:"plot-qnparego-pareto-frontier-based-on-model-posterior",children:"Plot qNParEGO Pareto Frontier based on model posterior"}),"\n",(0,i.jsx)(t.p,{children:"The plotted points are samples from the fitted model's posterior, not observed samples."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'frontier = compute_posterior_pareto_frontier(\n    experiment=parego_experiment,\n    data=parego_experiment.fetch_data(),\n    primary_objective=metric_b,\n    secondary_objective=metric_a,\n    absolute_metrics=["a", "b"],\n    num_points=20,\n)\n\nrender(plot_pareto_frontier(frontier, CI_level=0.90))\n'})}),"\n",(0,i.jsx)(t.h2,{id:"plot-empirical-data",children:"Plot empirical data"}),"\n",(0,i.jsx)(t.h4,{id:"plot-observed-hypervolume-with-color-representing-the-iteration-that-a-point-was-generated-on",children:"Plot observed hypervolume, with color representing the iteration that a point was generated on."}),"\n",(0,i.jsx)(t.p,{children:"To examine optimization process from another perspective, we plot the collected\nobservations under each algorithm where the color corresponds to the BO iteration at\nwhich the point was collected. The plot on the right for $q$NEHVI shows that the\n$q$NEHVI quickly identifies the Pareto frontier and most of its evaluations are very\nclose to the Pareto frontier. $q$NParEGO also identifies has many observations close to\nthe Pareto frontier, but relies on optimizing random scalarizations, which is a less\nprincipled way of optimizing the Pareto front compared to $q$NEHVI, which explicitly\nattempts focuses on improving the Pareto front. Sobol generates random points and has\nfew points close to the Pareto front."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'import matplotlib\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.cm import ScalarMappable\n\n%matplotlib inline\n\n\nfig, axes = plt.subplots(1, 3, figsize=(20, 6))\nalgos = ["Sobol", "qNParEGO", "qNEHVI"]\noutcomes_list = [sobol_outcomes, parego_outcomes, ehvi_outcomes]\ncm = matplotlib.colormaps["viridis"]\nBATCH_SIZE = 1\n\nn_results = N_BATCH * BATCH_SIZE + N_INIT\nbatch_number = torch.cat(\n    [\n        torch.zeros(N_INIT),\n        torch.arange(1, N_BATCH + 1).repeat(BATCH_SIZE, 1).t().reshape(-1),\n    ]\n).numpy()\nfor i, train_obj in enumerate(outcomes_list):\n    x = i\n    sc = axes[x].scatter(\n        train_obj[:n_results, 0],\n        train_obj[:n_results, 1],\n        c=batch_number[:n_results],\n        alpha=0.8,\n    )\n    axes[x].set_title(algos[i])\n    axes[x].set_xlabel("Objective 1")\n    axes[x].set_xlim(-150, 5)\n    axes[x].set_ylim(-15, 0)\naxes[0].set_ylabel("Objective 2")\nnorm = plt.Normalize(batch_number.min(), batch_number.max())\nsm = ScalarMappable(norm=norm, cmap=cm)\nsm.set_array([])\nfig.subplots_adjust(right=0.9)\ncbar_ax = fig.add_axes([0.93, 0.15, 0.01, 0.7])\ncbar = fig.colorbar(sm, cax=cbar_ax)\ncbar.ax.set_title("Iteration")\n'})}),"\n",(0,i.jsx)(t.h1,{id:"hypervolume-statistics",children:"Hypervolume statistics"}),"\n",(0,i.jsx)(t.p,{children:"The hypervolume of the space dominated by points that dominate the reference point."}),"\n",(0,i.jsx)(t.h4,{id:"plot-the-results",children:"Plot the results"}),"\n",(0,i.jsx)(t.p,{children:"The plot below shows a common metric of multi-objective optimization performance when\nthe true Pareto frontier is known: the log difference between the hypervolume of the\ntrue Pareto front and the hypervolume of the approximate Pareto front identified by each\nalgorithm. The log hypervolume difference is plotted at each step of the optimization\nfor each of the algorithms."}),"\n",(0,i.jsx)(t.p,{children:"The plot show that $q$NEHVI vastly outperforms $q$NParEGO which outperforms the Sobol\nbaseline."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'iters = np.arange(1, N_BATCH + 1)\nlog_hv_difference_sobol = np.log10(branin_currin.max_hv - np.asarray(sobol_hv_list))[\n    : N_BATCH + 1\n]\nlog_hv_difference_parego = np.log10(branin_currin.max_hv - np.asarray(parego_hv_list))[\n    : N_BATCH + 1\n]\nlog_hv_difference_ehvi = np.log10(branin_currin.max_hv - np.asarray(ehvi_hv_list))[\n    : N_BATCH + 1\n]\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nax.plot(iters, log_hv_difference_sobol, label="Sobol", linewidth=1.5)\nax.plot(iters, log_hv_difference_parego, label="qNParEGO", linewidth=1.5)\nax.plot(iters, log_hv_difference_ehvi, label="qNEHVI", linewidth=1.5)\nax.set(\n    xlabel="number of observations (beyond initial points)",\n    ylabel="Log Hypervolume Difference",\n)\nax.legend(loc="lower right")\n'})})]})}function d(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},1023:(e,t,n)=>{n.d(t,{A:()=>m});n(6540);var i,o=new Uint8Array(16);function r(){if(!i&&!(i="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return i(o)}const a=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;const s=function(e){return"string"==typeof e&&a.test(e)};for(var l=[],c=0;c<256;++c)l.push((c+256).toString(16).substr(1));const p=function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,n=(l[e[t+0]]+l[e[t+1]]+l[e[t+2]]+l[e[t+3]]+"-"+l[e[t+4]]+l[e[t+5]]+"-"+l[e[t+6]]+l[e[t+7]]+"-"+l[e[t+8]]+l[e[t+9]]+"-"+l[e[t+10]]+l[e[t+11]]+l[e[t+12]]+l[e[t+13]]+l[e[t+14]]+l[e[t+15]]).toLowerCase();if(!s(n))throw TypeError("Stringified UUID is invalid");return n};const h=function(e,t,n){var i=(e=e||{}).random||(e.rng||r)();if(i[6]=15&i[6]|64,i[8]=63&i[8]|128,t){n=n||0;for(var o=0;o<16;++o)t[n+o]=i[o];return t}return p(i)};var d=n(4848);const m=function(e){return(0,d.jsxs)("div",{style:{backgroundColor:"lightgray",marginBottom:"var(--ifm-leading)",borderRadius:"var(--ifm-global-radius)",boxShadow:"var(--ifm-global-shadow-lw)",overflow:"hidden",padding:"10px",font:"var(--ifm-code-font-size) / var(--ifm-pre-line-height) var(--ifm-font-family-monospace)"},children:[(0,d.jsx)("span",{style:{color:"red"},children:"Out: "}),(0,d.jsx)("pre",{style:{margin:"0px",backgroundColor:"inherit"},children:e.children.split("\n").map((function(e){return(0,d.jsx)("p",{style:{marginBottom:"0px"},children:e},h())}))})]})}},8987:(e,t,n)=>{n.d(t,{A:()=>r});n(6540);var i=n(8774),o=n(4848);const r=function(e){var t=e.githubUrl,n=e.colabUrl;return(0,o.jsxs)("div",{className:"link-buttons",children:[(0,o.jsx)(i.A,{to:t,children:"Open in GitHub"}),(0,o.jsx)("div",{}),(0,o.jsx)(i.A,{to:n,children:"Run in Google Colab"})]})}},290:(e,t,n)=>{n(6540);var i=n(3259),o=n.n(i),r=(n(2303),n(4848));o()({loader:function(){return n.e(236).then(n.bind(n,1236))},loading:function(e){return e.timedOut?(0,r.jsx)("blockquote",{children:"Error: Loading Plotly timed out."}):(0,r.jsx)("div",{children:"loading..."})},timeout:1e4})},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var i=n(6540);const o={},r=i.createContext(o);function a(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);