"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[6834],{22670:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var i=t(74848),a=t(28453),r=t(38987);t(31023),t(70290);const o={title:"Human-in-the-Loop Optimization",sidebar_label:"Human-in-the-Loop Optimization"},s="Using Ax for Human-in-the-loop Experimentation\xb6",l={id:"tutorials/human_in_the_loop/index",title:"Human-in-the-Loop Optimization",description:"<LinkButtons",source:"@site/versioned_docs/version-0.9.5/tutorials/human_in_the_loop/index.mdx",sourceDirName:"tutorials/human_in_the_loop",slug:"/tutorials/human_in_the_loop/",permalink:"/Ax/docs/tutorials/human_in_the_loop/",draft:!1,unlisted:!1,tags:[],version:"0.9.5",lastUpdatedBy:"Cristian Lara",lastUpdatedAt:1733177729e3,frontMatter:{title:"Human-in-the-Loop Optimization",sidebar_label:"Human-in-the-Loop Optimization"},sidebar:"tutorials",previous:{title:"Bandit Optimization",permalink:"/Ax/docs/tutorials/factorial/"},next:{title:"RandomForest with ExternalGenerationNode",permalink:"/Ax/docs/tutorials/external_generation_node/"}},c={},d=[{value:"Experiment Setup",id:"experiment-setup",level:2},{value:"Initial Sobol Trial",id:"initial-sobol-trial",level:3},{value:"Experiment Analysis",id:"experiment-analysis",level:2},{value:"Model Fit",id:"model-fit",level:3},{value:"Candidate Generation",id:"candidate-generation",level:3},{value:"Change Objectives",id:"change-objectives",level:3},{value:"Creating a New Trial",id:"creating-a-new-trial",level:2}];function h(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.A,{githubUrl:"https://github.com/cristianlara/Ax/blob/0.9.5/tutorials/human_in_the_loop/human_in_the_loop.ipynb",colabUrl:"https://colab.research.google.com/github/cristianlara/Ax/blob/0.9.5/tutorials/human_in_the_loop/human_in_the_loop.ipynb"}),"\n",(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"using-ax-for-human-in-the-loop-experimentation",children:"Using Ax for Human-in-the-loop Experimentation\xb6"})}),"\n",(0,i.jsx)(n.p,{children:"While Ax can be used in as a fully automated service, generating and deploying\ncandidates Ax can be also used in a trial-by-trial fashion, allowing for human\noversight."}),"\n",(0,i.jsx)(n.p,{children:"Typically, human intervention in Ax is necessary when there are clear tradeoffs between\nmultiple metrics of interest. Condensing multiple outcomes of interest into a single\nscalar quantity can be really challenging. Instead, it can be useful to specify an\nobjective and constraints, and tweak these based on the information from the experiment."}),"\n",(0,i.jsx)(n.p,{children:"To facilitate this, Ax provides the following key features:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Constrained optimization"}),"\n",(0,i.jsx)(n.li,{children:"Interfaces for easily modifying optimization goals"}),"\n",(0,i.jsx)(n.li,{children:"Utilities for visualizing and deploying new trials composed of multiple\noptimizations."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"In this tutorial, we'll demonstrate how Ax enables users to explore these tradeoffs.\nWith an understanding of the tradeoffs present in our data, we'll then make use of the\nconstrained optimization utilities to generate candidates from multiple different\noptimization objectives, and create a conglomerate batch, with all of these candidates\nin together in one trial."}),"\n",(0,i.jsx)(n.h2,{id:"experiment-setup",children:"Experiment Setup"}),"\n",(0,i.jsx)(n.p,{children:"For this tutorial, we will assume our experiment has already been created."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import os\n\nfrom ax import (\n    Data,\n    Metric,\n    OptimizationConfig,\n    Objective,\n    OutcomeConstraint,\n    ComparisonOp,\n    json_load,\n)\nfrom ax.modelbridge.cross_validation import cross_validate\nfrom ax.modelbridge.registry import Models\nfrom ax.plot.diagnostic import tile_cross_validation\nfrom ax.plot.scatter import plot_multiple_metrics, tile_fitted\nfrom ax.utils.notebook.plotting import render, init_notebook_plotting\n\nimport pandas as pd\n\ninit_notebook_plotting()\n"})}),"\n",(0,i.jsxs)(n.p,{children:["NOTE: The path below assumes the tutorial is being run either from the root directory of\nthe Ax package or from the ",(0,i.jsx)(n.code,{children:"human_in_the_loop"})," directory that this tutorial lives in.\nThis is needed since the jupyter notebooks may change active directory during runtime,\nmaking it tricky to find the file in a consistent way."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'curr_dir = os.getcwd()\nif "human_in_the_loop" not in curr_dir:\n    curr_dir = os.path.join(curr_dir, "tutorials", "human_in_the_loop")\nexperiment = json_load.load_experiment(os.path.join(curr_dir, "hitl_exp.json"))\n'})}),"\n",(0,i.jsx)(n.h3,{id:"initial-sobol-trial",children:"Initial Sobol Trial"}),"\n",(0,i.jsxs)(n.p,{children:["Bayesian Optimization experiments almost always begin with a set of random points. In\nthis experiment, these points were chosen via a Sobol sequence, accessible via the\n",(0,i.jsx)(n.code,{children:"ModelBridge"})," factory."]}),"\n",(0,i.jsxs)(n.p,{children:["A collection of points run and analyzed together form a ",(0,i.jsx)(n.code,{children:"BatchTrial"}),". A ",(0,i.jsx)(n.code,{children:"Trial"})," object\nprovides metadata pertaining to the deployment of these points, including details such\nas when they were deployed, and the current status of their experiment."]}),"\n",(0,i.jsx)(n.p,{children:"Here, we see an initial experiment has finished running (COMPLETED status)."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"experiment.trials[0]\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"experiment.trials[0].time_created\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Number of arms in first experiment, including status_quo\nlen(experiment.trials[0].arms)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Sample arm configuration\nexperiment.trials[0].arms[0]\n"})}),"\n",(0,i.jsx)(n.h2,{id:"experiment-analysis",children:"Experiment Analysis"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Optimization Config"})}),"\n",(0,i.jsx)(n.p,{children:"An important construct for analyzing an experiment is an OptimizationConfig. An\nOptimizationConfig contains an objective, and outcome constraints. Experiment's can have\na default OptimizationConfig, but models can also take an OptimizationConfig as input\nindependent of the default."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Objective:"})," A metric to optimize, along with a direction to optimize (default:\nmaximize)"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Outcome Constraint:"})," A metric to constrain, along with a constraint direction (<= or\n>=), as well as a bound."]}),"\n",(0,i.jsxs)(n.p,{children:["Let's start with a simple OptimizationConfig. By default, our objective metric will be\nmaximized, but can be minimized by setting the ",(0,i.jsx)(n.code,{children:"minimize"})," flag. Our outcome constraint\nwill, by default, be evaluated as a relative percentage change. This percentage change\nis computed relative to the experiment's status quo arm."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"experiment.status_quo\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'objective_metric = Metric(name="metric_1")\nconstraint_metric = Metric(name="metric_2")\n\nexperiment.optimization_config = OptimizationConfig(\n    objective=Objective(objective_metric, minimize=False),\n    outcome_constraints=[\n        OutcomeConstraint(metric=constraint_metric, op=ComparisonOp.LEQ, bound=5),\n    ],\n)\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Data"})}),"\n",(0,i.jsx)(n.p,{children:"Another critical piece of analysis is data itself! Ax data follows a standard format,\nshown below. This format is imposed upon the underlying data structure, which is a\nPandas DataFrame."}),"\n",(0,i.jsx)(n.p,{children:"A key set of fields are required for all data, for use with Ax models."}),"\n",(0,i.jsx)(n.p,{children:"It's a good idea to double check our data before fitting models -- let's make sure all\nof our expected metrics and arms are present."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'data = Data(pd.read_json(os.path.join(curr_dir, "hitl_data.json")))\ndata.df.head()\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'data.df["arm_name"].unique()\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'data.df["metric_name"].unique()\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Search Space"})}),"\n",(0,i.jsx)(n.p,{children:"The final component necessary for human-in-the-loop optimization is a SearchSpace. A\nSearchSpace defines the feasible region for our parameters, as well as their types."}),"\n",(0,i.jsx)(n.p,{children:"Here, we have both parameters and a set of constraints on those parameters."}),"\n",(0,i.jsx)(n.p,{children:"Without a SearchSpace, our models are unable to generate new candidates. By default, the\nmodels will read the search space off of the experiment, when they are told to generate\ncandidates. SearchSpaces can also be specified by the user at this time. Sometimes, the\nfirst round of an experiment is too restrictive--perhaps the experimenter was too\ncautious when defining their initial ranges for exploration! In this case, it can be\nuseful to generate candidates from new, expanded search spaces, beyond that specified in\nthe experiment."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"experiment.search_space.parameters\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"experiment.search_space.parameter_constraints\n"})}),"\n",(0,i.jsx)(n.h3,{id:"model-fit",children:"Model Fit"}),"\n",(0,i.jsxs)(n.p,{children:["Fitting a Modular BoTorch Model will allow us to predict new candidates based on our\nfirst Sobol batch. Here, we make use of the default settings for ",(0,i.jsx)(n.code,{children:"BOTORCH_MODULAR"}),"\ndefined in the ModelBridge registry (uses BoTorch's ",(0,i.jsx)(n.code,{children:"SingleTaskGP"})," and\n",(0,i.jsx)(n.code,{children:"qLogNoisyExpectedImprovement"})," by default for single objective optimization)."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"gp = Models.BOTORCH_MODULAR(\n    search_space=experiment.search_space,\n    experiment=experiment,\n    data=data,\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"We can validate the model fits using cross validation, shown below for each metric of\ninterest. Here, our model fits leave something to be desired--the tail ends of each\nmetric are hard to model. In this situation, there are three potential actions to take:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Increase the amount of traffic in this experiment, to reduce the measurement noise."}),"\n",(0,i.jsx)(n.li,{children:"Increase the number of points run in the random batch, to assist the GP in covering\nthe space."}),"\n",(0,i.jsx)(n.li,{children:"Reduce the number of parameters tuned at one time."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"However, away from the tail effects, the fits do show a strong correlations, so we will\nproceed with candidate generation."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"cv_result = cross_validate(gp)\nrender(tile_cross_validation(cv_result))\n"})}),"\n",(0,i.jsx)(n.p,{children:"The parameters from the initial batch have a wide range of effects on the metrics of\ninterest, as shown from the outcomes from our fitted GP model."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"render(tile_fitted(gp, rel=True))\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'METRIC_X_AXIS = "metric_1"\nMETRIC_Y_AXIS = "metric_2"\n\nrender(\n    plot_multiple_metrics(\n        gp,\n        metric_x=METRIC_X_AXIS,\n        metric_y=METRIC_Y_AXIS,\n    )\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"candidate-generation",children:"Candidate Generation"}),"\n",(0,i.jsx)(n.p,{children:"With our fitted GPEI model, we can optimize EI (Expected Improvement) based on any\noptimization config. We can start with our initial optimization config, and aim to\nsimply maximize the playback smoothness, without worrying about the constraint on\nquality."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"unconstrained = gp.gen(\n    n=3,\n    optimization_config=OptimizationConfig(\n        objective=Objective(objective_metric, minimize=False),\n    ),\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Let's plot the tradeoffs again, but with our new arms."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'render(\n    plot_multiple_metrics(\n        gp,\n        metric_x=METRIC_X_AXIS,\n        metric_y=METRIC_Y_AXIS,\n        generator_runs_dict={\n            "unconstrained": unconstrained,\n        },\n    )\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"change-objectives",children:"Change Objectives"}),"\n",(0,i.jsx)(n.p,{children:"With our unconstrained optimization, we generate some candidates which are pretty\npromising with respect to our objective! However, there is a clear regression in our\nconstraint metric, above our initial 5% desired constraint. Let's add that constraint\nback in."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"constraint_5 = OutcomeConstraint(metric=constraint_metric, op=ComparisonOp.LEQ, bound=5)\nconstraint_5_results = gp.gen(\n    n=3,\n    optimization_config=OptimizationConfig(\n        objective=Objective(objective_metric, minimize=False), outcome_constraints=[constraint_5]\n    ),\n)\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This yields a ",(0,i.jsx)(n.em,{children:"GeneratorRun"}),", which contains points according to our specified\noptimization config, along with metadata about how the points were generated. Let's plot\nthe tradeoffs in these new points."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from ax.plot.scatter import plot_multiple_metrics\n\nrender(\n    plot_multiple_metrics(\n        gp,\n        metric_x=METRIC_X_AXIS,\n        metric_y=METRIC_Y_AXIS,\n        generator_runs_dict={"constraint_5": constraint_5_results},\n    )\n)\n'})}),"\n",(0,i.jsx)(n.p,{children:"It is important to note that the treatment of constraints in GP EI is probabilistic. The\nacquisition function weights our objective by the probability that each constraint is\nfeasible. Thus, we may allow points with a very small probability of violating the\nconstraint to be generated, as long as the chance of the points increasing our objective\nis high enough."}),"\n",(0,i.jsx)(n.p,{children:"You can see above that the point estimate for each point is significantly below a 5%\nincrease in the constraint metric, but that there is uncertainty in our prediction, and\nthe tail probabilities do include probabilities of small regressions beyond 5%."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"constraint_1 = OutcomeConstraint(metric=constraint_metric, op=ComparisonOp.LEQ, bound=1)\nconstraint_1_results = gp.gen(\n    n=3,\n    optimization_config=OptimizationConfig(\n        objective=Objective(objective_metric, minimize=False),\n        outcome_constraints=[constraint_1],\n    ),\n)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'render(\n    plot_multiple_metrics(\n        gp,\n        metric_x=METRIC_X_AXIS,\n        metric_y=METRIC_Y_AXIS,\n        generator_runs_dict={\n            "constraint_1": constraint_1_results,\n        },\n    )\n)\n'})}),"\n",(0,i.jsx)(n.p,{children:"Finally, let's view all three sets of candidates together."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'render(\n    plot_multiple_metrics(\n        gp,\n        metric_x=METRIC_X_AXIS,\n        metric_y=METRIC_Y_AXIS,\n        generator_runs_dict={\n            "unconstrained": unconstrained,\n            "loose_constraint": constraint_5_results,\n            "tight_constraint": constraint_1_results,\n        },\n    )\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"creating-a-new-trial",children:"Creating a New Trial"}),"\n",(0,i.jsxs)(n.p,{children:["Having done the analysis and candidate generation for three different optimization\nconfigs, we can easily create a new ",(0,i.jsx)(n.code,{children:"BatchTrial"})," which combines the candidates from\nthese three different optimizations. Each set of candidates looks promising -- the point\nestimates are higher along both metric values than in the previous batch. However, there\nis still a good bit of uncertainty in our predictions. It is hard to choose between the\ndifferent constraint settings without reducing this noise, so we choose to run a new\ntrial with all three constraint settings. However, we're generally convinced that the\ntight constraint is too conservative. We'd still like to reduce our uncertainty in that\nregion, but we'll only take one arm from that set."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# We can add entire generator runs, when constructing a new trial.\ntrial = (\n    experiment.new_batch_trial()\n    .add_generator_run(unconstrained)\n    .add_generator_run(constraint_5_results)\n)\n\n# Or, we can hand-pick arms.\ntrial.add_arm(constraint_1_results.arms[0])\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The arms are combined into a single trial, along with the ",(0,i.jsx)(n.code,{children:"status_quo"})," arm. Their\ngenerator can be accessed from the trial as well."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"experiment.trials[1].arms\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The original ",(0,i.jsx)(n.code,{children:"GeneratorRuns"})," can be accessed from within the trial as well. This is\nuseful for later analyses, allowing introspection of the ",(0,i.jsx)(n.code,{children:"OptimizationConfig"})," used for\ngeneration (as well as other information, e.g. ",(0,i.jsx)(n.code,{children:"SearchSpace"})," used for generation)."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"experiment.trials[1]._generator_run_structs\n"})}),"\n",(0,i.jsx)(n.p,{children:"Here, we can see the unconstrained set-up used for our first set of candidates."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"experiment.trials[1]._generator_run_structs[0].generator_run.optimization_config\n"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},31023:(e,n,t)=>{t.d(n,{A:()=>m});t(96540);var i,a=new Uint8Array(16);function r(){if(!i&&!(i="undefined"!=typeof crypto&&crypto.getRandomValues&&crypto.getRandomValues.bind(crypto)||"undefined"!=typeof msCrypto&&"function"==typeof msCrypto.getRandomValues&&msCrypto.getRandomValues.bind(msCrypto)))throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");return i(a)}const o=/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;const s=function(e){return"string"==typeof e&&o.test(e)};for(var l=[],c=0;c<256;++c)l.push((c+256).toString(16).substr(1));const d=function(e){var n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:0,t=(l[e[n+0]]+l[e[n+1]]+l[e[n+2]]+l[e[n+3]]+"-"+l[e[n+4]]+l[e[n+5]]+"-"+l[e[n+6]]+l[e[n+7]]+"-"+l[e[n+8]]+l[e[n+9]]+"-"+l[e[n+10]]+l[e[n+11]]+l[e[n+12]]+l[e[n+13]]+l[e[n+14]]+l[e[n+15]]).toLowerCase();if(!s(t))throw TypeError("Stringified UUID is invalid");return t};const h=function(e,n,t){var i=(e=e||{}).random||(e.rng||r)();if(i[6]=15&i[6]|64,i[8]=63&i[8]|128,n){t=t||0;for(var a=0;a<16;++a)n[t+a]=i[a];return n}return d(i)};var p=t(74848);const m=function(e){return(0,p.jsxs)("div",{style:{backgroundColor:"var(--ifm-pre-background)",marginBottom:"10px",borderRadius:"var(--ifm-global-radius)",overflow:"hidden",padding:"5px",font:"var(--ifm-code-font-size) / var(--ifm-pre-line-height) var(--ifm-font-family-monospace)"},children:[(0,p.jsx)("span",{style:{color:"red"},children:"Out: "}),(0,p.jsx)("pre",{style:{margin:"0px",backgroundColor:"inherit",padding:"8px"},children:e.children.split("\n").map((function(e){return(0,p.jsx)("p",{style:{marginBottom:"0px"},children:e},h())}))})]})}},38987:(e,n,t)=>{t.d(n,{A:()=>o});t(96540);var i=t(28774),a=t(43186),r=t(74848);const o=function(e){var n=e.githubUrl,t=e.colabUrl;return(0,r.jsxs)("div",{className:"margin-top--sm margin-bottom--lg",children:[(0,r.jsxs)(i.A,{to:n,className:"button button--outline button--primary margin-right--xs",children:["Open in GitHub",(0,r.jsx)(a.A,{})]}),(0,r.jsxs)(i.A,{to:t,className:"button button--outline button--primary margin--xs",children:["Run in Google Colab",(0,r.jsx)(a.A,{})]})]})}},70290:(e,n,t)=>{t.d(n,{z:()=>l});var i=t(96540),a=t(53259),r=t.n(a),o=(t(92303),t(74848));var s=r()({loader:function(){return t.e(1236).then(t.bind(t,91236))},loading:function(e){return e.timedOut?(0,o.jsx)("blockquote",{children:"Error: Loading Plotly timed out."}):(0,o.jsx)("div",{children:"loading..."})},timeout:1e4}),l=i.memo((function(e){var n=e.data;return(0,o.jsx)("div",{className:"plotly-figure",style:{"overflow-x":"auto"},children:(0,o.jsx)(s,{data:n.data,layout:n.layout})})}))},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var i=t(96540);const a={},r=i.createContext(a);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);